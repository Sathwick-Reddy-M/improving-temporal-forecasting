{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before date conversion:\n",
      "              Datetime  ABI   ACT  AMA  ALB  JFK  LGA\n",
      "0  1949-01-01 00:00:00  6.1  10.6  2.2 -3.3 -3.3 -3.9\n",
      "1  1949-01-01 01:00:00  3.3   6.7  1.1 -3.3 -3.3 -3.9\n",
      "2  1949-01-01 02:00:00  2.2   5.6  0.6 -3.3 -3.3 -3.9\n",
      "3  1949-01-01 03:00:00  1.7   4.4  0.0 -2.8 -3.3 -3.9\n",
      "4  1949-01-01 04:00:00  1.7   3.9  1.1 -2.8 -3.3 -3.9\n",
      "After filtering for >=2010 and date conversion:\n",
      "                Datetime  ABI  ACT  AMA  ALB  JFK  LGA\n",
      "470398  2010-01-01 00:00  1.1  6.7 -0.6 -1.7  1.1  1.1\n",
      "470399  2010-01-01 01:00  1.1  6.1 -3.3 -1.7  1.1  1.1\n",
      "470400  2010-01-01 02:00  1.7  5.6 -3.9 -1.7  0.6  1.1\n",
      "470401  2010-01-01 03:00  1.1  5.0 -3.9 -1.7  0.6  1.1\n",
      "470402  2010-01-01 04:00  1.1  4.4 -5.0 -1.1  0.6  0.6\n",
      "Modified file saved as S:\\spatiotemporal-analysis\\spacetimeformer-main\\spacetimeformer\\data\\temperature-v1_modified.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the downloaded file in Kaggle environment\n",
    "file_path = \"S:\\\\spatiotemporal-analysis\\\\spacetimeformer-main\\\\spacetimeformer\\\\data\\\\temperature-v1.csv\"\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the structure of the data\n",
    "print(\"Before date conversion:\")\n",
    "print(data.head())\n",
    "\n",
    "# Convert the 'Datetime' column to datetime\n",
    "data['Datetime'] = pd.to_datetime(data['Datetime'])\n",
    "\n",
    "# Filter the data to keep only rows from the year 2010\n",
    "data = data[data['Datetime'].dt.year >= 2010]\n",
    "\n",
    "# Format the 'Datetime' column to the desired format: %Y-%m-%d %H:%M\n",
    "data['Datetime'] = data['Datetime'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "# Display the first few rows after filtering and conversion\n",
    "print(\"After filtering for >=2010 and date conversion:\")\n",
    "print(data.head())\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file\n",
    "output_file_path = \"S:\\\\spatiotemporal-analysis\\\\spacetimeformer-main\\\\spacetimeformer\\\\data\\\\temperature-v1_modified.csv\"\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Confirm that the file has been saved\n",
    "print(f\"Modified file saved as {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State 1</th>\n",
       "      <th>State 2</th>\n",
       "      <th>Physical Distance (km)</th>\n",
       "      <th>Normalized Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QLD</td>\n",
       "      <td>QLD</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QLD</td>\n",
       "      <td>NSW</td>\n",
       "      <td>1004.958524</td>\n",
       "      <td>0.805895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QLD</td>\n",
       "      <td>SA</td>\n",
       "      <td>1138.614306</td>\n",
       "      <td>0.874667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QLD</td>\n",
       "      <td>TAS</td>\n",
       "      <td>2179.251774</td>\n",
       "      <td>2.449765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QLD</td>\n",
       "      <td>VIC</td>\n",
       "      <td>1603.659847</td>\n",
       "      <td>1.586073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NSW</td>\n",
       "      <td>QLD</td>\n",
       "      <td>1004.958524</td>\n",
       "      <td>0.805895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NSW</td>\n",
       "      <td>NSW</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NSW</td>\n",
       "      <td>SA</td>\n",
       "      <td>1033.954847</td>\n",
       "      <td>0.971088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NSW</td>\n",
       "      <td>TAS</td>\n",
       "      <td>1199.579094</td>\n",
       "      <td>1.838309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NSW</td>\n",
       "      <td>VIC</td>\n",
       "      <td>715.254517</td>\n",
       "      <td>0.924033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SA</td>\n",
       "      <td>QLD</td>\n",
       "      <td>1138.614306</td>\n",
       "      <td>0.874667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SA</td>\n",
       "      <td>NSW</td>\n",
       "      <td>1033.954847</td>\n",
       "      <td>0.971088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SA</td>\n",
       "      <td>SA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SA</td>\n",
       "      <td>TAS</td>\n",
       "      <td>1640.642214</td>\n",
       "      <td>2.319568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SA</td>\n",
       "      <td>VIC</td>\n",
       "      <td>1022.361110</td>\n",
       "      <td>1.233518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TAS</td>\n",
       "      <td>QLD</td>\n",
       "      <td>2179.251774</td>\n",
       "      <td>2.449765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TAS</td>\n",
       "      <td>NSW</td>\n",
       "      <td>1199.579094</td>\n",
       "      <td>1.838309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TAS</td>\n",
       "      <td>SA</td>\n",
       "      <td>1640.642214</td>\n",
       "      <td>2.319568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TAS</td>\n",
       "      <td>TAS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TAS</td>\n",
       "      <td>VIC</td>\n",
       "      <td>633.941443</td>\n",
       "      <td>1.521615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>VIC</td>\n",
       "      <td>QLD</td>\n",
       "      <td>1603.659847</td>\n",
       "      <td>1.586073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VIC</td>\n",
       "      <td>NSW</td>\n",
       "      <td>715.254517</td>\n",
       "      <td>0.924033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VIC</td>\n",
       "      <td>SA</td>\n",
       "      <td>1022.361110</td>\n",
       "      <td>1.233518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>VIC</td>\n",
       "      <td>TAS</td>\n",
       "      <td>633.941443</td>\n",
       "      <td>1.521615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>VIC</td>\n",
       "      <td>VIC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State 1 State 2  Physical Distance (km)  Normalized Distance\n",
       "0      QLD     QLD                0.000000             0.000000\n",
       "1      QLD     NSW             1004.958524             0.805895\n",
       "2      QLD      SA             1138.614306             0.874667\n",
       "3      QLD     TAS             2179.251774             2.449765\n",
       "4      QLD     VIC             1603.659847             1.586073\n",
       "5      NSW     QLD             1004.958524             0.805895\n",
       "6      NSW     NSW                0.000000             0.000000\n",
       "7      NSW      SA             1033.954847             0.971088\n",
       "8      NSW     TAS             1199.579094             1.838309\n",
       "9      NSW     VIC              715.254517             0.924033\n",
       "10      SA     QLD             1138.614306             0.874667\n",
       "11      SA     NSW             1033.954847             0.971088\n",
       "12      SA      SA                0.000000             0.000000\n",
       "13      SA     TAS             1640.642214             2.319568\n",
       "14      SA     VIC             1022.361110             1.233518\n",
       "15     TAS     QLD             2179.251774             2.449765\n",
       "16     TAS     NSW             1199.579094             1.838309\n",
       "17     TAS      SA             1640.642214             2.319568\n",
       "18     TAS     TAS                0.000000             0.000000\n",
       "19     TAS     VIC              633.941443             1.521615\n",
       "20     VIC     QLD             1603.659847             1.586073\n",
       "21     VIC     NSW              715.254517             0.924033\n",
       "22     VIC      SA             1022.361110             1.233518\n",
       "23     VIC     TAS              633.941443             1.521615\n",
       "24     VIC     VIC                0.000000             0.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Haversine formula to compute the distance between two points given their latitudes and longitudes\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Radius of the Earth in kilometers\n",
    "    R = 6371.0\n",
    "    \n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1_rad = np.radians(lat1)\n",
    "    lon1_rad = np.radians(lon1)\n",
    "    lat2_rad = np.radians(lat2)\n",
    "    lon2_rad = np.radians(lon2)\n",
    "    \n",
    "    # Differences in coordinates\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    \n",
    "    # Haversine formula\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    \n",
    "    # Distance in kilometers\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Function to calculate the effective radius based on area\n",
    "def effective_radius(area):\n",
    "    return np.sqrt(area / np.pi)\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'state': ['QLD', 'NSW', 'SA', 'TAS', 'VIC'],\n",
    "    'lat': [-22.5752, -31.2532, -30.0002, -42.0409, -36.9848],\n",
    "    'long': [144.0848, 146.9211, 136.2092, 146.8087, 143.3906],\n",
    "    'area_km_sq': [1729742, 801150, 984321, 68401, 227444]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the effective radii for each state\n",
    "df['effective_radius'] = df['area_km_sq'].apply(effective_radius)\n",
    "\n",
    "# Initialize list to store both normalized and physical distances\n",
    "distances = []\n",
    "\n",
    "# Loop through pairs of states to calculate distances\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(df)):\n",
    "        # Get the coordinates, areas and radii\n",
    "        lat1, lon1, r1 = df.iloc[i]['lat'], df.iloc[i]['long'], df.iloc[i]['effective_radius']\n",
    "        lat2, lon2, r2 = df.iloc[j]['lat'], df.iloc[j]['long'], df.iloc[j]['effective_radius']\n",
    "        \n",
    "        # Calculate the physical distance between the centroids using the Haversine formula\n",
    "        distance = haversine(lat1, lon1, lat2, lon2)\n",
    "        \n",
    "        # Calculate the normalized distance\n",
    "        D_norm = distance / (r1 + r2)\n",
    "        \n",
    "        # Append the results to the list\n",
    "        distances.append({\n",
    "            'State 1': df.iloc[i]['state'],\n",
    "            'State 2': df.iloc[j]['state'],\n",
    "            'Physical Distance (km)': distance,\n",
    "            'Normalized Distance': D_norm\n",
    "        })\n",
    "\n",
    "# Create a DataFrame with both physical and normalized distances\n",
    "distances_df = pd.DataFrame(distances)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "distances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State 1</th>\n",
       "      <th>State 2</th>\n",
       "      <th>Physical Distance (km)</th>\n",
       "      <th>Normalized Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NSW</td>\n",
       "      <td>NSW</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NSW</td>\n",
       "      <td>QLD</td>\n",
       "      <td>1004.958524</td>\n",
       "      <td>0.805895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NSW</td>\n",
       "      <td>VIC</td>\n",
       "      <td>715.254517</td>\n",
       "      <td>0.924033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NSW</td>\n",
       "      <td>SA</td>\n",
       "      <td>1033.954847</td>\n",
       "      <td>0.971088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NSW</td>\n",
       "      <td>TAS</td>\n",
       "      <td>1199.579094</td>\n",
       "      <td>1.838309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State 1 State 2  Physical Distance (km)  Normalized Distance\n",
       "6     NSW     NSW                0.000000             0.000000\n",
       "5     NSW     QLD             1004.958524             0.805895\n",
       "9     NSW     VIC              715.254517             0.924033\n",
       "7     NSW      SA             1033.954847             0.971088\n",
       "8     NSW     TAS             1199.579094             1.838309"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_df[distances_df['State 1'] == 'NSW'].sort_values('Normalized Distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python S:\\\\spatiotemporal-analysis\\\\spacetimeformer-main\\\\spacetimeformer\\\\train.py spacetimeformer asos --context_points 128 --target_points 40 --run_name spacetimeformer_asos --batch_size 32 --warmup_steps 1000 --d_model 200 --d_ff 700 --enc_layers 1 --dec_layers 1 --dropout_emb .1 --dropout_ff .3 --d_qk 30 --d_v 30 --n_heads 10 --patience 10 --decay_factor .8 --data_path S:\\\\spatiotemporal-analysis\\\\spacetimeformer-main\\\\spacetimeformer\\\\data\\\\temperature-v1_modified.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def subset_csv(src_path: str, dest_path: str, columns: list):\n",
    "    \"\"\"\n",
    "    Reads a CSV file from src_path, extracts the specified columns, and writes the subset to dest_path.\n",
    "    \n",
    "    Parameters:\n",
    "        src_path (str): Path to the source CSV file.\n",
    "        dest_path (str): Path to save the subset CSV file.\n",
    "        columns (list): List of column names to extract from the source CSV.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(src_path)\n",
    "    \n",
    "    # Create a subset of the DataFrame with the specified columns\n",
    "    subset = df[columns]\n",
    "    \n",
    "    # Save the subset to the destination CSV file\n",
    "    subset.to_csv(dest_path, index=False)\n",
    "    print(f\"Subset saved to {dest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset saved to /Users/sathwick/SDrive/ISU/S25/599/aemo_nsw_vlc.csv\n",
      "Subset saved to /Users/sathwick/SDrive/ISU/S25/599/aemo_nsw_qld.csv\n"
     ]
    }
   ],
   "source": [
    "subset_csv('/Users/sathwick/SDrive/ISU/S25/599/aemo_merged.csv', '/Users/sathwick/SDrive/ISU/S25/599/aemo_nsw_vlc.csv', ['SETTLEMENTDATE', \"TOTALDEMAND_NSW\", \"RRP_NSW\", \"TOTALDEMAND_VIC\", \"RRP_VIC\",])\n",
    "subset_csv('/Users/sathwick/SDrive/ISU/S25/599/aemo_merged.csv', '/Users/sathwick/SDrive/ISU/S25/599/aemo_nsw_qld.csv', ['SETTLEMENTDATE', \"TOTALDEMAND_NSW\", \"RRP_NSW\", \"TOTALDEMAND_QLD\", \"RRP_QLD\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SETTLEMENTDATE</th>\n",
       "      <th>TOTALDEMAND_NSW</th>\n",
       "      <th>RRP_NSW</th>\n",
       "      <th>TOTALDEMAND_VIC</th>\n",
       "      <th>RRP_VIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-01 00:00</td>\n",
       "      <td>6529.375000</td>\n",
       "      <td>19.210000</td>\n",
       "      <td>4485.130000</td>\n",
       "      <td>14.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-01 01:00</td>\n",
       "      <td>6145.710000</td>\n",
       "      <td>18.195000</td>\n",
       "      <td>4055.830000</td>\n",
       "      <td>12.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-01 02:00</td>\n",
       "      <td>5782.555000</td>\n",
       "      <td>16.450000</td>\n",
       "      <td>3701.360000</td>\n",
       "      <td>10.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-01 03:00</td>\n",
       "      <td>5600.055000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>3488.495000</td>\n",
       "      <td>6.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-01 04:00</td>\n",
       "      <td>5619.520000</td>\n",
       "      <td>15.955000</td>\n",
       "      <td>3455.595000</td>\n",
       "      <td>4.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88100</th>\n",
       "      <td>2025-02-18 20:00</td>\n",
       "      <td>7977.682500</td>\n",
       "      <td>106.371667</td>\n",
       "      <td>5107.343333</td>\n",
       "      <td>93.497500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88101</th>\n",
       "      <td>2025-02-18 21:00</td>\n",
       "      <td>7653.483333</td>\n",
       "      <td>100.095833</td>\n",
       "      <td>4648.734167</td>\n",
       "      <td>87.070833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88102</th>\n",
       "      <td>2025-02-18 22:00</td>\n",
       "      <td>7361.791667</td>\n",
       "      <td>97.980000</td>\n",
       "      <td>4341.420833</td>\n",
       "      <td>84.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88103</th>\n",
       "      <td>2025-02-18 23:00</td>\n",
       "      <td>7002.186667</td>\n",
       "      <td>96.224167</td>\n",
       "      <td>4404.169167</td>\n",
       "      <td>86.157500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88104</th>\n",
       "      <td>2025-02-19 00:00</td>\n",
       "      <td>6896.590000</td>\n",
       "      <td>85.940000</td>\n",
       "      <td>4305.290000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88105 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SETTLEMENTDATE  TOTALDEMAND_NSW     RRP_NSW  TOTALDEMAND_VIC  \\\n",
       "0      2015-02-01 00:00      6529.375000   19.210000      4485.130000   \n",
       "1      2015-02-01 01:00      6145.710000   18.195000      4055.830000   \n",
       "2      2015-02-01 02:00      5782.555000   16.450000      3701.360000   \n",
       "3      2015-02-01 03:00      5600.055000   14.200000      3488.495000   \n",
       "4      2015-02-01 04:00      5619.520000   15.955000      3455.595000   \n",
       "...                 ...              ...         ...              ...   \n",
       "88100  2025-02-18 20:00      7977.682500  106.371667      5107.343333   \n",
       "88101  2025-02-18 21:00      7653.483333  100.095833      4648.734167   \n",
       "88102  2025-02-18 22:00      7361.791667   97.980000      4341.420833   \n",
       "88103  2025-02-18 23:00      7002.186667   96.224167      4404.169167   \n",
       "88104  2025-02-19 00:00      6896.590000   85.940000      4305.290000   \n",
       "\n",
       "         RRP_VIC  \n",
       "0      14.590000  \n",
       "1      12.925000  \n",
       "2      10.440000  \n",
       "3       6.660000  \n",
       "4       4.380000  \n",
       "...          ...  \n",
       "88100  93.497500  \n",
       "88101  87.070833  \n",
       "88102  84.615000  \n",
       "88103  86.157500  \n",
       "88104  79.000000  \n",
       "\n",
       "[88105 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/Users/sathwick/SDrive/ISU/S25/599/aemo_nsw_vlc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SETTLEMENTDATE</th>\n",
       "      <th>TOTALDEMAND_NSW</th>\n",
       "      <th>RRP_NSW</th>\n",
       "      <th>TOTALDEMAND_QLD</th>\n",
       "      <th>RRP_QLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-01 00:00</td>\n",
       "      <td>6529.375000</td>\n",
       "      <td>19.210000</td>\n",
       "      <td>5687.755000</td>\n",
       "      <td>17.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-01 01:00</td>\n",
       "      <td>6145.710000</td>\n",
       "      <td>18.195000</td>\n",
       "      <td>5349.120000</td>\n",
       "      <td>16.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-01 02:00</td>\n",
       "      <td>5782.555000</td>\n",
       "      <td>16.450000</td>\n",
       "      <td>5148.620000</td>\n",
       "      <td>14.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-01 03:00</td>\n",
       "      <td>5600.055000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>5045.510000</td>\n",
       "      <td>13.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-01 04:00</td>\n",
       "      <td>5619.520000</td>\n",
       "      <td>15.955000</td>\n",
       "      <td>5066.075000</td>\n",
       "      <td>14.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88100</th>\n",
       "      <td>2025-02-18 20:00</td>\n",
       "      <td>7977.682500</td>\n",
       "      <td>106.371667</td>\n",
       "      <td>8026.143333</td>\n",
       "      <td>112.365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88101</th>\n",
       "      <td>2025-02-18 21:00</td>\n",
       "      <td>7653.483333</td>\n",
       "      <td>100.095833</td>\n",
       "      <td>7663.199167</td>\n",
       "      <td>102.720833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88102</th>\n",
       "      <td>2025-02-18 22:00</td>\n",
       "      <td>7361.791667</td>\n",
       "      <td>97.980000</td>\n",
       "      <td>7187.470833</td>\n",
       "      <td>102.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88103</th>\n",
       "      <td>2025-02-18 23:00</td>\n",
       "      <td>7002.186667</td>\n",
       "      <td>96.224167</td>\n",
       "      <td>6736.655000</td>\n",
       "      <td>100.227500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88104</th>\n",
       "      <td>2025-02-19 00:00</td>\n",
       "      <td>6896.590000</td>\n",
       "      <td>85.940000</td>\n",
       "      <td>6531.180000</td>\n",
       "      <td>87.480000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88105 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SETTLEMENTDATE  TOTALDEMAND_NSW     RRP_NSW  TOTALDEMAND_QLD  \\\n",
       "0      2015-02-01 00:00      6529.375000   19.210000      5687.755000   \n",
       "1      2015-02-01 01:00      6145.710000   18.195000      5349.120000   \n",
       "2      2015-02-01 02:00      5782.555000   16.450000      5148.620000   \n",
       "3      2015-02-01 03:00      5600.055000   14.200000      5045.510000   \n",
       "4      2015-02-01 04:00      5619.520000   15.955000      5066.075000   \n",
       "...                 ...              ...         ...              ...   \n",
       "88100  2025-02-18 20:00      7977.682500  106.371667      8026.143333   \n",
       "88101  2025-02-18 21:00      7653.483333  100.095833      7663.199167   \n",
       "88102  2025-02-18 22:00      7361.791667   97.980000      7187.470833   \n",
       "88103  2025-02-18 23:00      7002.186667   96.224167      6736.655000   \n",
       "88104  2025-02-19 00:00      6896.590000   85.940000      6531.180000   \n",
       "\n",
       "          RRP_QLD  \n",
       "0       17.855000  \n",
       "1       16.100000  \n",
       "2       14.420000  \n",
       "3       13.025000  \n",
       "4       14.620000  \n",
       "...           ...  \n",
       "88100  112.365000  \n",
       "88101  102.720833  \n",
       "88102  102.015000  \n",
       "88103  100.227500  \n",
       "88104   87.480000  \n",
       "\n",
       "[88105 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/Users/sathwick/SDrive/ISU/S25/599/aemo_nsw_qld.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_columns_and_save(input_file_path, selected_columns, output_file_path):\n",
    "    # Read the original dataframe from the input CSV file\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    \n",
    "    # Filter the dataframe to only include the selected columns\n",
    "    df_filtered = df[selected_columns]\n",
    "    \n",
    "    # Save the filtered dataframe to the specified output file path\n",
    "    df_filtered.to_csv(output_file_path, index=False)\n",
    "    print(f\"Filtered dataframe saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\NSW.csv\n",
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\TAS.csv\n",
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\QLD.csv\n",
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\VIC.csv\n",
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\SA.csv\n",
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\NSW_QLD.csv\n",
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\NSW_VIC.csv\n",
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\QLD_SA.csv\n",
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\TAS_VIC.csv\n",
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\NSW_SA_VIC.csv\n",
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\NSW_QLD_VIC.csv\n",
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\NSW_QLD_SA.csv\n",
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\NSW_TAS_VIC.csv\n",
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\NSW_QLD_SA_VIC.csv\n",
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\NSW_SA_TAS_VIC.csv\n",
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\NSW_QLD_SA_TAS_VIC.csv\n"
     ]
    }
   ],
   "source": [
    "l = [['NSW'],\n",
    " ['TAS'],\n",
    " ['QLD'],\n",
    " ['VIC'],\n",
    " ['SA'],\n",
    " ['NSW', 'QLD'],\n",
    " ['NSW', 'VIC'],\n",
    " ['QLD', 'SA'],\n",
    " ['TAS', 'VIC'],\n",
    " ['NSW', 'SA', 'VIC'],\n",
    " ['NSW', 'QLD', 'VIC'],\n",
    " ['NSW', 'QLD', 'SA'],\n",
    " ['NSW', 'TAS', 'VIC'],\n",
    " ['NSW', 'QLD', 'SA', 'VIC'],\n",
    " ['NSW', 'SA', 'TAS', 'VIC'],\n",
    " ['NSW', 'QLD', 'SA', 'TAS', 'VIC']]\n",
    "\n",
    "for i in l:\n",
    "    input_file_path = 'C:\\\\Users\\\\vm-user\\\\Downloads\\\\aemo_merged.csv'\n",
    "    selected_columns = ['SETTLEMENTDATE']\n",
    "    for j in i:\n",
    "        selected_columns.append(f'TOTALDEMAND_{j}')\n",
    "        selected_columns.append(f'RRP_{j}')\n",
    "    output_file_path = f'C:\\\\Users\\\\vm-user\\\\Downloads\\\\{\"_\".join(i)}.csv'\n",
    "    filter_columns_and_save(input_file_path, selected_columns, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\aemo_nsw_qld_vic.csv\n"
     ]
    }
   ],
   "source": [
    "filter_columns_and_save(\n",
    "    \"C:\\\\Users\\\\vm-user\\\\Downloads\\\\aemo_merged.csv\", \n",
    "    [\"SETTLEMENTDATE\", \"TOTALDEMAND_NSW\", \"RRP_NSW\", \"TOTALDEMAND_QLD\", \"RRP_QLD\", \"TOTALDEMAND_VIC\", \"RRP_VIC\"], \n",
    "    \"C:\\\\Users\\\\vm-user\\\\Downloads\\\\aemo_nsw_qld_vic.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataframe saved to C:\\Users\\vm-user\\Downloads\\aemo_nsw_qld_vic_tas.csv\n"
     ]
    }
   ],
   "source": [
    "filter_columns_and_save(\n",
    "    \"C:\\\\Users\\\\vm-user\\\\Downloads\\\\aemo_merged.csv\", \n",
    "    [\"SETTLEMENTDATE\", \"TOTALDEMAND_NSW\", \"RRP_NSW\", \"TOTALDEMAND_QLD\", \"RRP_QLD\", \"TOTALDEMAND_VIC\", \"RRP_VIC\", \"TOTALDEMAND_TAS\", \"RRP_TAS\"], \n",
    "    \"C:\\\\Users\\\\vm-user\\\\Downloads\\\\aemo_nsw_qld_vic_tas.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries = pd.read_csv(\"C:\\\\Users\\\\vm-user\\\\Downloads\\\\all_countries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO3 Code</th>\n",
       "      <th>Datetime (UTC)</th>\n",
       "      <th>Datetime (Local)</th>\n",
       "      <th>Price (EUR/MWhe)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>22.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>BEL</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>36.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Czechia</td>\n",
       "      <td>CZE</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>24.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>18.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>EST</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>23.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country ISO3 Code       Datetime (UTC)     Datetime (Local)  \\\n",
       "0  Austria       AUT  2015-01-01 00:00:00  2015-01-01 01:00:00   \n",
       "1  Belgium       BEL  2015-01-01 00:00:00  2015-01-01 01:00:00   \n",
       "2  Czechia       CZE  2015-01-01 00:00:00  2015-01-01 01:00:00   \n",
       "3  Denmark       DNK  2015-01-01 00:00:00  2015-01-01 01:00:00   \n",
       "4  Estonia       EST  2015-01-01 00:00:00  2015-01-01 02:00:00   \n",
       "\n",
       "   Price (EUR/MWhe)  \n",
       "0             22.34  \n",
       "1             36.56  \n",
       "2             24.20  \n",
       "3             18.29  \n",
       "4             23.37  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_map = {\n",
    "    'Austria': 'AT',\n",
    "    'Belgium': 'BE',\n",
    "    'Bulgaria': 'BG',\n",
    "    'Croatia': 'HR',\n",
    "    'Czechia': 'CZ',\n",
    "    'Denmark': 'DK',\n",
    "    'Estonia': 'EE',\n",
    "    'Finland': 'FI',\n",
    "    'France': 'FR',\n",
    "    'Germany': 'DE',\n",
    "    'Greece': 'GR',\n",
    "    'Hungary': 'HU',\n",
    "    'Ireland': 'IE',\n",
    "    'Italy': 'IT',\n",
    "    'Latvia': 'LV',\n",
    "    'Lithuania': 'LT',\n",
    "    'Luxembourg': 'LU',\n",
    "    'Montenegro': 'ME',\n",
    "    'Netherlands': 'NL',\n",
    "    'North Macedonia': 'MK',\n",
    "    'Norway': 'NO',\n",
    "    'Poland': 'PL',\n",
    "    'Portugal': 'PT',\n",
    "    'Romania': 'RO',\n",
    "    'Serbia': 'RS',\n",
    "    'Slovakia': 'SK',\n",
    "    'Slovenia': 'SI',\n",
    "    'Spain': 'ES',\n",
    "    'Sweden': 'SE',\n",
    "    'Switzerland': 'CH',\n",
    "    'United Kingdom': 'GB'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 31)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(countries_map.values())), len(countries_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique two-letter country codes in Country column: ['AT' 'BE' 'CZ' 'DK' 'EE' 'FI' 'FR' 'DE' 'GR' 'HU' 'IT' 'LV' 'LT' 'LU'\n",
      " 'NL' 'NO' 'PL' 'PT' 'RO' 'SK' 'SI' 'ES' 'SE' 'CH' 'GB' 'BG' 'RS' 'HR'\n",
      " 'ME' 'MK' 'IE']\n"
     ]
    }
   ],
   "source": [
    "# Replace the Country column values with their two-letter codes\n",
    "all_countries['Country'] = all_countries['Country'].map(countries_map)\n",
    "\n",
    "# Optionally, check the result\n",
    "print(\"Unique two-letter country codes in Country column:\", all_countries['Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 31)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(countries_map.values())), len(countries_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def pivot_and_resample(df):\n",
    "    \"\"\"\n",
    "    Transforms the dataset by pivoting countries into columns and resampling the time series.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe containing country-wise electricity prices.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Resampled dataframe with hourly prices for each country as separate columns.\n",
    "    \"\"\"\n",
    "    # Convert 'Datetime (UTC)' to datetime format\n",
    "    df['Datetime (UTC)'] = pd.to_datetime(df['Datetime (UTC)'])\n",
    "\n",
    "    # Drop 'Datetime (Local)' as it's not needed\n",
    "    df = df.drop(columns=['Datetime (Local)'])\n",
    "\n",
    "    # Rename 'Price (EUR/MWhe)' to 'Price'\n",
    "    df = df.rename(columns={'Price (EUR/MWhe)': 'Price'})\n",
    "\n",
    "    # Pivot the table to make countries as columns\n",
    "    df_pivoted = df.pivot_table(index='Datetime (UTC)', columns='Country', values='Price', aggfunc='mean')\n",
    "\n",
    "    # Resample to ensure hourly intervals from min to max timestamp\n",
    "    df_resampled = df_pivoted.resample('h').mean()\n",
    "\n",
    "    # Reset index to bring datetime back as a column\n",
    "    df_resampled.reset_index(inplace=True)\n",
    "\n",
    "    return df_resampled\n",
    "\n",
    "# Example usage\n",
    "final_df = pivot_and_resample(all_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df.copy()\n",
    "for col in df.columns[1:]:\n",
    "    non_null_series = df[col].dropna()  # Remove NaN values to find the first non-null value\n",
    "    if not non_null_series.empty:\n",
    "        first_index = non_null_series.index[0]  # Find the first non-null value's index\n",
    "        first_value = non_null_series.iloc[0]  # Get the first non-null value\n",
    "        \n",
    "        # Replace consecutive occurrences with NaN, starting from first_index\n",
    "        for i in range(first_index + 1, len(df)):\n",
    "            if pd.isna(df[col].iloc[i]) or df[col].iloc[i] != first_value:\n",
    "                break  # Stop if a different value or NaN appears\n",
    "            df.loc[i-1, col] = float(\"nan\")  # Set previous consecutive occurrences to NaN\n",
    "\n",
    "# Remove initial rows where all country columns are NaN (excluding 'Datetime')\n",
    "df_cleaned = df.dropna(subset=df.columns[1:], how='all').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_1hr_intervals(time_series):\n",
    "    time_series = pd.to_datetime(time_series).sort_values()\n",
    "    expected_interval = pd.Timedelta(hours=1)\n",
    "    return (time_series.diff().dropna() == expected_interval).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_1hr_intervals(df_cleaned['Datetime (UTC)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Country</th>\n",
       "      <th>Datetime (UTC)</th>\n",
       "      <th>AT</th>\n",
       "      <th>BE</th>\n",
       "      <th>BG</th>\n",
       "      <th>CH</th>\n",
       "      <th>CZ</th>\n",
       "      <th>DE</th>\n",
       "      <th>DK</th>\n",
       "      <th>EE</th>\n",
       "      <th>ES</th>\n",
       "      <th>...</th>\n",
       "      <th>MK</th>\n",
       "      <th>NL</th>\n",
       "      <th>NO</th>\n",
       "      <th>PL</th>\n",
       "      <th>PT</th>\n",
       "      <th>RO</th>\n",
       "      <th>RS</th>\n",
       "      <th>SE</th>\n",
       "      <th>SI</th>\n",
       "      <th>SK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.43</td>\n",
       "      <td>24.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.29</td>\n",
       "      <td>23.37</td>\n",
       "      <td>48.10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.37</td>\n",
       "      <td>23.25</td>\n",
       "      <td>24.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.08</td>\n",
       "      <td>22.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.04</td>\n",
       "      <td>19.33</td>\n",
       "      <td>47.33</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.33</td>\n",
       "      <td>22.20</td>\n",
       "      <td>22.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.47</td>\n",
       "      <td>20.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.60</td>\n",
       "      <td>17.66</td>\n",
       "      <td>42.27</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.66</td>\n",
       "      <td>19.56</td>\n",
       "      <td>20.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.83</td>\n",
       "      <td>19.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.95</td>\n",
       "      <td>17.53</td>\n",
       "      <td>38.41</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.53</td>\n",
       "      <td>18.88</td>\n",
       "      <td>19.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.26</td>\n",
       "      <td>17.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.50</td>\n",
       "      <td>18.07</td>\n",
       "      <td>35.72</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.07</td>\n",
       "      <td>18.39</td>\n",
       "      <td>17.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88818</th>\n",
       "      <td>2025-02-17 18:00:00</td>\n",
       "      <td>214.41</td>\n",
       "      <td>215.46</td>\n",
       "      <td>224.35</td>\n",
       "      <td>203.38</td>\n",
       "      <td>216.50</td>\n",
       "      <td>214.10</td>\n",
       "      <td>215.38</td>\n",
       "      <td>219.35</td>\n",
       "      <td>215.52</td>\n",
       "      <td>...</td>\n",
       "      <td>148.2</td>\n",
       "      <td>215.43</td>\n",
       "      <td>94.09</td>\n",
       "      <td>218.20</td>\n",
       "      <td>215.52</td>\n",
       "      <td>216.86</td>\n",
       "      <td>223.78</td>\n",
       "      <td>157.34</td>\n",
       "      <td>216.46</td>\n",
       "      <td>217.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88819</th>\n",
       "      <td>2025-02-17 19:00:00</td>\n",
       "      <td>178.47</td>\n",
       "      <td>177.95</td>\n",
       "      <td>224.35</td>\n",
       "      <td>171.35</td>\n",
       "      <td>179.08</td>\n",
       "      <td>181.78</td>\n",
       "      <td>177.87</td>\n",
       "      <td>180.91</td>\n",
       "      <td>200.00</td>\n",
       "      <td>...</td>\n",
       "      <td>148.2</td>\n",
       "      <td>177.93</td>\n",
       "      <td>88.03</td>\n",
       "      <td>180.90</td>\n",
       "      <td>200.00</td>\n",
       "      <td>179.47</td>\n",
       "      <td>195.21</td>\n",
       "      <td>130.24</td>\n",
       "      <td>179.03</td>\n",
       "      <td>179.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88820</th>\n",
       "      <td>2025-02-17 20:00:00</td>\n",
       "      <td>159.23</td>\n",
       "      <td>155.38</td>\n",
       "      <td>224.35</td>\n",
       "      <td>159.98</td>\n",
       "      <td>151.40</td>\n",
       "      <td>161.50</td>\n",
       "      <td>155.19</td>\n",
       "      <td>155.95</td>\n",
       "      <td>155.62</td>\n",
       "      <td>...</td>\n",
       "      <td>148.2</td>\n",
       "      <td>155.30</td>\n",
       "      <td>82.59</td>\n",
       "      <td>154.09</td>\n",
       "      <td>155.62</td>\n",
       "      <td>165.32</td>\n",
       "      <td>174.31</td>\n",
       "      <td>110.05</td>\n",
       "      <td>161.59</td>\n",
       "      <td>172.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88821</th>\n",
       "      <td>2025-02-17 21:00:00</td>\n",
       "      <td>159.23</td>\n",
       "      <td>139.51</td>\n",
       "      <td>224.35</td>\n",
       "      <td>159.98</td>\n",
       "      <td>151.40</td>\n",
       "      <td>161.50</td>\n",
       "      <td>155.19</td>\n",
       "      <td>155.95</td>\n",
       "      <td>140.00</td>\n",
       "      <td>...</td>\n",
       "      <td>148.2</td>\n",
       "      <td>139.39</td>\n",
       "      <td>82.59</td>\n",
       "      <td>154.09</td>\n",
       "      <td>155.62</td>\n",
       "      <td>161.88</td>\n",
       "      <td>174.31</td>\n",
       "      <td>110.05</td>\n",
       "      <td>161.59</td>\n",
       "      <td>172.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88822</th>\n",
       "      <td>2025-02-17 22:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88823 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Country      Datetime (UTC)      AT      BE      BG      CH      CZ      DE  \\\n",
       "0       2015-01-01 00:00:00     NaN     NaN     NaN   43.43   24.20     NaN   \n",
       "1       2015-01-01 01:00:00     NaN     NaN     NaN   38.08   22.06     NaN   \n",
       "2       2015-01-01 02:00:00     NaN     NaN     NaN   35.47   20.27     NaN   \n",
       "3       2015-01-01 03:00:00     NaN     NaN     NaN   30.83   19.17     NaN   \n",
       "4       2015-01-01 04:00:00     NaN     NaN     NaN   28.26   17.90     NaN   \n",
       "...                     ...     ...     ...     ...     ...     ...     ...   \n",
       "88818   2025-02-17 18:00:00  214.41  215.46  224.35  203.38  216.50  214.10   \n",
       "88819   2025-02-17 19:00:00  178.47  177.95  224.35  171.35  179.08  181.78   \n",
       "88820   2025-02-17 20:00:00  159.23  155.38  224.35  159.98  151.40  161.50   \n",
       "88821   2025-02-17 21:00:00  159.23  139.51  224.35  159.98  151.40  161.50   \n",
       "88822   2025-02-17 22:00:00     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "Country      DK      EE      ES  ...     MK      NL     NO      PL      PT  \\\n",
       "0         18.29   23.37   48.10  ...    NaN     NaN  27.35     NaN   48.10   \n",
       "1         16.04   19.33   47.33  ...    NaN     NaN  27.23     NaN   47.33   \n",
       "2         14.60   17.66   42.27  ...    NaN     NaN  27.15     NaN   42.27   \n",
       "3         14.95   17.53   38.41  ...    NaN     NaN  27.14     NaN   38.41   \n",
       "4         14.50   18.07   35.72  ...    NaN     NaN  27.29     NaN   35.72   \n",
       "...         ...     ...     ...  ...    ...     ...    ...     ...     ...   \n",
       "88818    215.38  219.35  215.52  ...  148.2  215.43  94.09  218.20  215.52   \n",
       "88819    177.87  180.91  200.00  ...  148.2  177.93  88.03  180.90  200.00   \n",
       "88820    155.19  155.95  155.62  ...  148.2  155.30  82.59  154.09  155.62   \n",
       "88821    155.19  155.95  140.00  ...  148.2  139.39  82.59  154.09  155.62   \n",
       "88822       NaN     NaN     NaN  ...    NaN     NaN    NaN     NaN     NaN   \n",
       "\n",
       "Country      RO      RS      SE      SI      SK  \n",
       "0           NaN     NaN   23.37   23.25   24.20  \n",
       "1           NaN     NaN   19.33   22.20   22.06  \n",
       "2           NaN     NaN   17.66   19.56   20.27  \n",
       "3           NaN     NaN   17.53   18.88   19.17  \n",
       "4           NaN     NaN   18.07   18.39   17.90  \n",
       "...         ...     ...     ...     ...     ...  \n",
       "88818    216.86  223.78  157.34  216.46  217.09  \n",
       "88819    179.47  195.21  130.24  179.03  179.71  \n",
       "88820    165.32  174.31  110.05  161.59  172.18  \n",
       "88821    161.88  174.31  110.05  161.59  172.18  \n",
       "88822       NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[88823 rows x 32 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_and_clean_dataframe(df, selected_columns):\n",
    "    \"\"\"\n",
    "    Filters the given DataFrame to retain only the selected columns, \n",
    "    and removes initial and bottom-most rows where all selected columns are NaN.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "        selected_columns (list): List of column names to retain.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # Ensure 'Datetime (UTC)' is included in the filtered columns\n",
    "    filtered_columns = ['Datetime (UTC)'] + selected_columns if 'Datetime (UTC)' in df.columns else selected_columns\n",
    "    df_filtered = df[filtered_columns]\n",
    "\n",
    "    # Drop initial rows where all selected columns (excluding 'Datetime') are NaN\n",
    "    start_index = df_filtered[selected_columns].first_valid_index()\n",
    "    df_cleaned = df_filtered.loc[start_index:].reset_index(drop=True)\n",
    "    \n",
    "    # Drop bottom-most rows where all selected columns (excluding 'Datetime') are NaN\n",
    "    end_index = df_cleaned[selected_columns].last_valid_index()\n",
    "    df_cleaned = df_cleaned.loc[:end_index].reset_index(drop=True)\n",
    "    df_cleaned.fillna(10**6, inplace=True)  # Replace NaNs with a large number\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# List of countries\n",
    "countries = ['Austria', 'Belgium', 'Czechia', 'Denmark', 'Estonia', 'Finland',\n",
    "'France', 'Germany', 'Greece', 'Hungary', 'Italy', 'Latvia',\n",
    "'Lithuania', 'Luxembourg', 'Netherlands', 'Norway', 'Poland',\n",
    "'Portugal', 'Romania', 'Slovakia', 'Slovenia', 'Spain', 'Sweden',\n",
    "'Switzerland', 'United Kingdom', 'Bulgaria', 'Serbia', 'Croatia',\n",
    "'Montenegro', 'North Macedonia', 'Ireland']\n",
    "\n",
    "lat = [47.516231, 50.503887, 49.817492, 56.26392, 58.595272, 61.92411,\n",
    "       46.227638, 51.165691, 39.074208, 47.162494, 41.87194, 56.879635,\n",
    "       55.169438, 49.815273, 52.132633, 60.472024, 51.919438, 39.399872,\n",
    "       45.943161, 48.669026, 46.151241, 40.463667, 60.128161, 46.818188,\n",
    "       55.378051, 42.733883, 44.016521, 45.1, 42.708678, 41.608635, 53.41291]\n",
    "\n",
    "long = [14.550072, 4.469936, 15.472962, 9.501785, 25.013607, 25.748151,\n",
    "        2.213749, 10.451526, 21.824312, 19.503304, 12.56738, 24.603189,\n",
    "        23.881275, 6.129583, 5.291266, 8.468946, 19.145136, -8.224454,\n",
    "        24.96676, 19.699024, 14.995463, -3.74922, 18.643501, 8.227512,\n",
    "        -3.435973, 25.48583, 21.005859, 15.2, 19.37439, 21.745275, -8.24389]\n",
    "\n",
    "area_km_sq = [82520, 30280, 77187, 42434, 42388, 303815, \n",
    "       640427, 349390, 128900, 91260, 295717, 62230,\n",
    "       62610, 2574, 33893, 366704, 304255,\n",
    "       91606, 230080, 48080, 20151, 498980, 407284,\n",
    "       39510, 242741, 108489, 88499, 55974,\n",
    "       13452, 25220, 68883]\n",
    "\n",
    "eu_data = {\n",
    "    'countries': countries,\n",
    "    'lat': lat,\n",
    "    'long': long,\n",
    "    'area_km_sq': area_km_sq\n",
    "}\n",
    "\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Radius of the Earth in kilometers\n",
    "    R = 6371.0\n",
    "    \n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1_rad = np.radians(lat1)\n",
    "    lon1_rad = np.radians(lon1)\n",
    "    lat2_rad = np.radians(lat2)\n",
    "    lon2_rad = np.radians(lon2)\n",
    "    \n",
    "    # Differences in coordinates\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    \n",
    "    # Haversine formula\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    \n",
    "    # Distance in kilometers\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Function to calculate the effective radius based on area\n",
    "def effective_radius(area):\n",
    "    return np.sqrt(area / np.pi)\n",
    "\n",
    "# Prepare the data into a DataFrame\n",
    "eu_df = pd.DataFrame(eu_data)\n",
    "\n",
    "# Calculate the effective radius for each country\n",
    "eu_df['effective_radius'] = eu_df['area_km_sq'].apply(effective_radius)\n",
    "\n",
    "# Initialize list to store both normalized and physical distances\n",
    "distances = []\n",
    "\n",
    "# Loop through pairs of countries to calculate distances\n",
    "for i in range(len(eu_df)):\n",
    "    for j in range(len(eu_df)):\n",
    "        # Get the coordinates, areas and radii\n",
    "        lat1, lon1, r1 = eu_df.iloc[i]['lat'], eu_df.iloc[i]['long'], eu_df.iloc[i]['effective_radius']\n",
    "        lat2, lon2, r2 = eu_df.iloc[j]['lat'], eu_df.iloc[j]['long'], eu_df.iloc[j]['effective_radius']\n",
    "        \n",
    "        # Calculate the physical distance between the centroids using the Haversine formula\n",
    "        distance = haversine(lat1, lon1, lat2, lon2)\n",
    "        \n",
    "        # Calculate the normalized distance\n",
    "        D_norm = distance / (r1 + r2)\n",
    "        \n",
    "        # Append the results to the list\n",
    "        distances.append({\n",
    "            'Country 1': eu_df.iloc[i]['countries'],\n",
    "            'Country 2': eu_df.iloc[j]['countries'],\n",
    "            'Physical Distance (km)': distance,\n",
    "            'Normalized Distance': D_norm\n",
    "        })\n",
    "\n",
    "distances_df = pd.DataFrame(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country 1</th>\n",
       "      <th>Country 2</th>\n",
       "      <th>Physical Distance (km)</th>\n",
       "      <th>Normalized Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>Austria</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>805.904977</td>\n",
       "      <td>3.096702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria</td>\n",
       "      <td>Czechia</td>\n",
       "      <td>264.705969</td>\n",
       "      <td>0.830276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>1031.865905</td>\n",
       "      <td>3.707866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria</td>\n",
       "      <td>Estonia</td>\n",
       "      <td>1412.866158</td>\n",
       "      <td>5.078086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>2364.256758</td>\n",
       "      <td>7.483855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>1923.646715</td>\n",
       "      <td>6.832214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>Montenegro</td>\n",
       "      <td>2350.806279</td>\n",
       "      <td>11.010233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>North Macedonia</td>\n",
       "      <td>2578.886347</td>\n",
       "      <td>10.850582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country 1        Country 2  Physical Distance (km)  Normalized Distance\n",
       "0     Austria          Austria                0.000000             0.000000\n",
       "1     Austria          Belgium              805.904977             3.096702\n",
       "2     Austria          Czechia              264.705969             0.830276\n",
       "3     Austria          Denmark             1031.865905             3.707866\n",
       "4     Austria          Estonia             1412.866158             5.078086\n",
       "..        ...              ...                     ...                  ...\n",
       "956   Ireland           Serbia             2364.256758             7.483855\n",
       "957   Ireland          Croatia             1923.646715             6.832214\n",
       "958   Ireland       Montenegro             2350.806279            11.010233\n",
       "959   Ireland  North Macedonia             2578.886347            10.850582\n",
       "960   Ireland          Ireland                0.000000             0.000000\n",
       "\n",
       "[961 rows x 4 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def closest_locations(df, location_col, other_location_col, distance_col, n):\n",
    "    # Create an empty dictionary to store the results\n",
    "    result = {}\n",
    "    \n",
    "    # Get unique values in the location column\n",
    "    unique_locations = df[location_col].unique()\n",
    "    \n",
    "    for location in unique_locations:\n",
    "        # Filter the dataframe for rows corresponding to the current location\n",
    "        location_df = df[df[location_col] == location]\n",
    "        \n",
    "        # Sort the rows based on the distance column\n",
    "        location_df = location_df.sort_values(by=distance_col)\n",
    "        \n",
    "        # Create subsets that progressively add the next 'n' closest locations\n",
    "        closest_n_locations = []\n",
    "            \n",
    "        num_steps = math.ceil(len(location_df) / n)\n",
    "        for i in range(1, num_steps + 1):\n",
    "            # Ensure we don't go past the length of the DataFrame\n",
    "            end_index = min(i * n, len(location_df))\n",
    "            closest_n_locations.append(location_df.iloc[:end_index][other_location_col].tolist())        # Add the result for the current location to the dictionary\n",
    "            result[location] = closest_n_locations\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Country 1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\vm-user\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Country 1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(distances_df[distances_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry 1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAustria\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormalized Distance\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\vm-user\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\vm-user\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Country 1'"
     ]
    }
   ],
   "source": [
    "len(distances_df[distances_df['Country 1'] == 'Austria'].sort_values(by='Normalized Distance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_subsets(closest_dict):\n",
    "    # Set to hold unique subsets (as sorted tuples)\n",
    "    unique_sets = set()\n",
    "\n",
    "    # Iterate over each location's list of subsets\n",
    "    for location, subsets in closest_dict.items():\n",
    "        for subset in subsets:\n",
    "            # Convert each subset to a sorted tuple (for order-insensitivity)\n",
    "            unique_sets.add(tuple(sorted(subset)))\n",
    "    \n",
    "    # Convert the set of unique tuples back to a list of lists\n",
    "    unique_subsets_list = [list(subset) for subset in unique_sets]\n",
    "    \n",
    "    # Sort the subsets by length\n",
    "    unique_subsets_list.sort(key=len)\n",
    "    \n",
    "    return unique_subsets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_subsets = unique_subsets(closest_locations(distances_df, 'Country 1', 'Country 2', 'Normalized Distance', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(country_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_BE.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_BG.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_HR.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_CZ.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_DK.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_EE.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_FI.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_FR.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_DE.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_GR.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_HU.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_IE.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_IT.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_LV.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_LT.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_LU.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_ME.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_NL.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_MK.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_NO.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_PL.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_PT.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_RO.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_RS.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_SK.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_SI.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_ES.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_SE.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_CH.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_HR_CZ_FR_DE_HU_IT_PL_RS_SI.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_CZ_DK_FI_FR_DE_NL_NO_PL_SE_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_BG_GR_HU_IT_ME_MK_PL_RO_RS_SK.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_BE_FR_DE_IT_LU_NL_PL_ES_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_CZ_EE_FI_DE_LV_LT_NO_PL_RO_SE.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_CZ_DE_HU_LV_LT_PL_RO_SK_SE.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_DK_EE_FI_DE_LV_LT_NO_PL_SE_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_BE_FR_DE_LU_NL_NO_PL_ES_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_HR_CZ_DE_HU_IT_PL_RO_RS_SK.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_BE_DK_FR_DE_IE_NL_NO_ES_SE_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_BG_HR_GR_HU_IT_ME_MK_PL_RO_RS.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_HR_FR_DE_GR_IT_ME_RS_SI_CH.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_CZ_DK_FR_DE_LU_NL_PL_CH.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_FR_DE_IE_IT_NO_PL_PT_ES_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_HR_CZ_DE_HU_PL_RO_RS_SK_SI.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_BE_DK_FR_DE_LU_NL_NO_PL_SE_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_HR_CZ_FR_DE_HU_PL_RO_SK_SI.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_BG_HR_GR_HU_IT_ME_MK_RO_RS_SK.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_BE_FR_DE_IE_NL_NO_PL_ES_SE_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_HR_CZ_FR_DE_HU_IT_PL_SK_SI.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_DK_EE_FI_FR_DE_LV_LT_NO_PL_SE.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BG_GR_HU_ME_MK_PL_RO_RS_SK.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_BE_FR_DE_IE_IT_NL_PT_ES_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_HR_CZ_FR_DE_IT_PL_ES_CH.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_DK_EE_FI_FR_DE_LV_NO_PL_SE_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_EE_FI_FR_DE_LV_LT_NO_PL_RO_SE.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_FR_DE_IT_LU_NL_ES_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_BG_HR_FR_GR_HU_IT_ME_MK_RO_RS.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BG_CZ_DK_EE_FI_FR_DE_HU_IT_LV_LT_NO_PL_RO_RS_SK_ES_SE_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_HR_CZ_FR_DE_HU_IT_LU_NL_NO_PL_RO_RS_SK_SI_ES_SE_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BG_HR_CZ_FI_FR_DE_GR_HU_IT_ME_MK_NO_PL_RO_RS_SK_SI_ES_SE.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BG_HR_CZ_DK_EE_FI_FR_DE_HU_IT_LV_LT_NO_PL_RO_RS_SK_SI_SE.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_CZ_DK_EE_FI_FR_DE_HU_IT_LV_LT_NL_NO_PL_RO_RS_SK_SE_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_CZ_DK_FI_FR_DE_HU_IE_IT_LU_NL_NO_PL_PT_RO_ES_SE_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_BG_HR_CZ_FR_DE_GR_HU_IT_LU_ME_MK_PL_RO_RS_SK_SI_ES_CH.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_HR_CZ_DK_FI_FR_DE_HU_IT_LT_NL_NO_PL_RO_RS_SK_SI_SE_CH.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BG_HR_CZ_DK_EE_FI_FR_DE_HU_IT_LV_LT_NO_PL_RO_RS_SK_SE_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_HR_CZ_DK_FR_DE_HU_IT_LT_LU_NL_NO_PL_RO_SK_SI_SE_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BG_HR_CZ_FI_FR_DE_GR_HU_IT_LV_LT_ME_MK_PL_RO_RS_SK_SI_SE.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BG_HR_CZ_FI_FR_DE_GR_HU_IT_LT_ME_MK_PL_RO_RS_SK_SI_ES_SE.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BG_HR_CZ_FR_DE_GR_HU_IT_LT_ME_MK_NO_PL_RO_RS_SK_SI_SE_CH.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_CZ_DK_EE_FI_FR_DE_HU_IE_LV_LT_NL_NO_PL_RO_SK_ES_SE_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_CZ_DK_EE_FI_FR_DE_HU_IE_IT_LV_LT_NL_NO_PL_RO_ES_SE_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_BG_HR_CZ_FR_DE_GR_HU_IT_ME_NO_PL_RO_RS_SK_SI_ES_SE_CH.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BG_CZ_DK_EE_FI_FR_DE_HU_IT_LV_LT_NL_NO_PL_RO_RS_SK_SE_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BG_HR_CZ_FR_DE_GR_HU_IT_ME_MK_NO_PL_RO_RS_SK_SI_ES_SE_CH.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BG_HR_CZ_FI_FR_DE_GR_HU_IT_LV_LT_ME_NO_PL_RO_RS_SK_SI_SE.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_HR_CZ_DK_FI_FR_DE_HU_IE_IT_LU_NL_NO_PL_RO_ES_SE_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_HR_CZ_DK_FR_DE_HU_IE_IT_LU_NL_NO_PL_PT_SI_ES_SE_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_HR_CZ_FR_DE_HU_IE_IT_LU_NL_NO_PL_PT_RO_SI_ES_SE_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_HR_CZ_FI_FR_DE_GR_HU_IE_IT_NL_NO_PL_PT_RO_ES_SE_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_BG_HR_CZ_DK_EE_FI_FR_DE_GR_HU_IT_LV_LT_LU_ME_NL_MK_NO_PL_PT_RO_RS_SK_SI_ES_SE_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_BG_HR_CZ_DK_EE_FI_FR_DE_GR_HU_IE_IT_LV_LT_ME_NL_MK_NO_PL_PT_RO_RS_SK_SI_ES_SE_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_BG_HR_CZ_DK_EE_FI_FR_DE_GR_HU_IE_IT_LV_LT_LU_ME_NL_NO_PL_PT_RO_RS_SK_SI_ES_SE_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_BG_HR_CZ_DK_EE_FI_FR_DE_GR_HU_IE_IT_LV_LT_LU_NL_MK_NO_PL_PT_RO_RS_SK_SI_ES_SE_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_BG_HR_CZ_DK_FI_FR_DE_GR_HU_IE_IT_LV_LT_LU_ME_NL_MK_NO_PL_PT_RO_RS_SK_SI_ES_SE_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_BG_HR_CZ_DK_EE_FI_FR_DE_GR_HU_IE_IT_LV_LT_LU_ME_NL_MK_NO_PL_RO_RS_SK_SI_ES_SE_CH_GB.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\eu_AT_BE_BG_HR_CZ_DK_EE_FI_FR_DE_GR_HU_IE_IT_LV_LT_LU_ME_NL_MK_NO_PL_PT_RO_RS_SK_SI_ES_SE_CH_GB.csv\n"
     ]
    }
   ],
   "source": [
    "df_cleaned['Datetime (UTC)'] = pd.to_datetime(df_cleaned['Datetime (UTC)'])\n",
    "df_cleaned['Datetime (UTC)'] = df_cleaned['Datetime (UTC)'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "for country in countries_map:\n",
    "    df_to_save = filter_and_clean_dataframe(df_cleaned, [countries_map[country]])\n",
    "    output_file_path = f\"C:\\\\Users\\\\vm-user\\\\Downloads\\\\eu_{countries_map[country]}.csv\"\n",
    "    # Print a message to see if the df has null values\n",
    "    if df_to_save.isnull().values.any():\n",
    "        print(f\"Warning: DataFrame for {countries_map[country]} contains null values.\")\n",
    "    df_to_save.to_csv(output_file_path, index=False)\n",
    "    print(f\"Saved: {output_file_path}\")\n",
    "\n",
    "for subset in country_subsets:\n",
    "    subset = [countries_map[country] for country in subset]\n",
    "    df_to_save = filter_and_clean_dataframe(df_cleaned, subset)\n",
    "    if df_to_save.isnull().values.any():\n",
    "        print(f\"Warning: DataFrame for {countries_map[country]} contains null values.\")\n",
    "    output_file_path = f\"C:\\\\Users\\\\vm-user\\\\Downloads\\\\eu_{'_'.join(subset)}.csv\"\n",
    "    df_to_save.to_csv(output_file_path, index=False)\n",
    "    print(f\"Saved: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 31)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(country_subsets[-1]) & set(country_subsets[-2])), len(set(country_subsets[-1]) | set(country_subsets[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(country_subsets[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYISO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyiso_data_df = pd.read_csv(\"C:\\\\Users\\\\vm-user\\\\Downloads\\\\nyiso.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List of countries\n",
    "regions = ['CAPITL', 'CENTRL', 'MHK VL', 'HUD VL', 'LONGIL', 'N.Y.C.', 'WEST', 'GENESE', 'NORTH', 'DUNWOD', 'MILLWD']\n",
    "\n",
    "long = [-73.9820406, -76.7300675, -75.1443401, -74.0753086, -73.0188755, -73.9247654, -78.6001935, -77.5107558, -74.0169224, -73.7846149, -73.8141997]\n",
    "\n",
    "lat = [43.1823555, 42.6094099, 43.4161459, 41.7112736, 40.8443418, 40.6944843, 42.6613719, 42.8694038, 44.5393904, 41.0350397, 41.2394963]\n",
    "\n",
    "area_km_sq = [41206.36, 39600.998, 74038.96, 18453.5, 5795.6, 1566.34, 29527.06, 9535.63, 15199.63, 905.66, 743.044]\n",
    "\n",
    "nyiso_data = {\n",
    "    'regions': regions,\n",
    "    'lat': lat,\n",
    "    'long': long,\n",
    "    'area_km_sq': area_km_sq\n",
    "}\n",
    "\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Radius of the Earth in kilometers\n",
    "    R = 6371.0\n",
    "    \n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1_rad = np.radians(lat1)\n",
    "    lon1_rad = np.radians(lon1)\n",
    "    lat2_rad = np.radians(lat2)\n",
    "    lon2_rad = np.radians(lon2)\n",
    "    \n",
    "    # Differences in coordinates\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    \n",
    "    # Haversine formula\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    \n",
    "    # Distance in kilometers\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Function to calculate the effective radius based on area\n",
    "def effective_radius(area):\n",
    "    return np.sqrt(area / np.pi)\n",
    "\n",
    "# Prepare the data into a DataFrame\n",
    "nyiso_df = pd.DataFrame(nyiso_data)\n",
    "\n",
    "# Calculate the effective radius for each country\n",
    "nyiso_df['effective_radius'] = nyiso_df['area_km_sq'].apply(effective_radius)\n",
    "\n",
    "# Initialize list to store both normalized and physical distances\n",
    "distances = []\n",
    "\n",
    "# Loop through pairs of countries to calculate distances\n",
    "for i in range(len(nyiso_df)):\n",
    "    for j in range(len(nyiso_df)):\n",
    "        # Get the coordinates, areas and radii\n",
    "        lat1, lon1, r1 = nyiso_df.iloc[i]['lat'], nyiso_df.iloc[i]['long'], nyiso_df.iloc[i]['effective_radius']\n",
    "        lat2, lon2, r2 = nyiso_df.iloc[j]['lat'], nyiso_df.iloc[j]['long'], nyiso_df.iloc[j]['effective_radius']\n",
    "        \n",
    "        # Calculate the physical distance between the centroids using the Haversine formula\n",
    "        distance = haversine(lat1, lon1, lat2, lon2)\n",
    "        \n",
    "        # Calculate the normalized distance\n",
    "        D_norm = distance / (r1 + r2)\n",
    "        \n",
    "        # Append the results to the list\n",
    "        distances.append({\n",
    "            'Region 1': nyiso_df.iloc[i]['regions'],\n",
    "            'Region 2': nyiso_df.iloc[j]['regions'],\n",
    "            'Physical Distance (km)': distance,\n",
    "            'Normalized Distance': D_norm\n",
    "        })\n",
    "\n",
    "distances_df = pd.DataFrame(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region 1</th>\n",
       "      <th>Region 2</th>\n",
       "      <th>Physical Distance (km)</th>\n",
       "      <th>Normalized Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>GENESE</td>\n",
       "      <td>GENESE</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>GENESE</td>\n",
       "      <td>CENTRL</td>\n",
       "      <td>70.004366</td>\n",
       "      <td>0.418268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>GENESE</td>\n",
       "      <td>WEST</td>\n",
       "      <td>91.892089</td>\n",
       "      <td>0.604392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>GENESE</td>\n",
       "      <td>MHK VL</td>\n",
       "      <td>201.382602</td>\n",
       "      <td>0.965355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>GENESE</td>\n",
       "      <td>CAPITL</td>\n",
       "      <td>288.925037</td>\n",
       "      <td>1.703364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>GENESE</td>\n",
       "      <td>HUD VL</td>\n",
       "      <td>310.512718</td>\n",
       "      <td>2.357101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>GENESE</td>\n",
       "      <td>NORTH</td>\n",
       "      <td>336.639628</td>\n",
       "      <td>2.700667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>GENESE</td>\n",
       "      <td>LONGIL</td>\n",
       "      <td>434.763550</td>\n",
       "      <td>4.434348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>GENESE</td>\n",
       "      <td>N.Y.C.</td>\n",
       "      <td>383.206844</td>\n",
       "      <td>4.949563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>GENESE</td>\n",
       "      <td>MILLWD</td>\n",
       "      <td>354.905062</td>\n",
       "      <td>5.036074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>GENESE</td>\n",
       "      <td>DUNWOD</td>\n",
       "      <td>369.472738</td>\n",
       "      <td>5.126422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Region 1 Region 2  Physical Distance (km)  Normalized Distance\n",
       "84   GENESE   GENESE                0.000000             0.000000\n",
       "78   GENESE   CENTRL               70.004366             0.418268\n",
       "83   GENESE     WEST               91.892089             0.604392\n",
       "79   GENESE   MHK VL              201.382602             0.965355\n",
       "77   GENESE   CAPITL              288.925037             1.703364\n",
       "80   GENESE   HUD VL              310.512718             2.357101\n",
       "85   GENESE    NORTH              336.639628             2.700667\n",
       "81   GENESE   LONGIL              434.763550             4.434348\n",
       "82   GENESE   N.Y.C.              383.206844             4.949563\n",
       "87   GENESE   MILLWD              354.905062             5.036074\n",
       "86   GENESE   DUNWOD              369.472738             5.126422"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_df[distances_df['Region 1'] == 'GENESE'].sort_values(by='Normalized Distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region 1</th>\n",
       "      <th>Region 2</th>\n",
       "      <th>Physical Distance (km)</th>\n",
       "      <th>Normalized Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAPITL</td>\n",
       "      <td>CAPITL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAPITL</td>\n",
       "      <td>MHK VL</td>\n",
       "      <td>97.585199</td>\n",
       "      <td>0.364065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CAPITL</td>\n",
       "      <td>NORTH</td>\n",
       "      <td>150.921305</td>\n",
       "      <td>0.819851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAPITL</td>\n",
       "      <td>HUD VL</td>\n",
       "      <td>163.755724</td>\n",
       "      <td>0.856605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAPITL</td>\n",
       "      <td>CENTRL</td>\n",
       "      <td>232.731997</td>\n",
       "      <td>1.026153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CAPITL</td>\n",
       "      <td>MILLWD</td>\n",
       "      <td>216.477736</td>\n",
       "      <td>1.666419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAPITL</td>\n",
       "      <td>GENESE</td>\n",
       "      <td>288.925037</td>\n",
       "      <td>1.703364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAPITL</td>\n",
       "      <td>LONGIL</td>\n",
       "      <td>271.874938</td>\n",
       "      <td>1.726432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAPITL</td>\n",
       "      <td>WEST</td>\n",
       "      <td>380.423305</td>\n",
       "      <td>1.798913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CAPITL</td>\n",
       "      <td>DUNWOD</td>\n",
       "      <td>239.325181</td>\n",
       "      <td>1.819885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CAPITL</td>\n",
       "      <td>N.Y.C.</td>\n",
       "      <td>276.679195</td>\n",
       "      <td>2.021685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Region 1 Region 2  Physical Distance (km)  Normalized Distance\n",
       "0    CAPITL   CAPITL                0.000000             0.000000\n",
       "2    CAPITL   MHK VL               97.585199             0.364065\n",
       "8    CAPITL    NORTH              150.921305             0.819851\n",
       "3    CAPITL   HUD VL              163.755724             0.856605\n",
       "1    CAPITL   CENTRL              232.731997             1.026153\n",
       "10   CAPITL   MILLWD              216.477736             1.666419\n",
       "7    CAPITL   GENESE              288.925037             1.703364\n",
       "4    CAPITL   LONGIL              271.874938             1.726432\n",
       "6    CAPITL     WEST              380.423305             1.798913\n",
       "9    CAPITL   DUNWOD              239.325181             1.819885\n",
       "5    CAPITL   N.Y.C.              276.679195             2.021685"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_df[distances_df['Region 1'] == 'CAPITL'].sort_values(by='Normalized Distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def average_distance_between_regions(regions: list, distances_df: pd.DataFrame, column = \"Normalized Distance\") -> float:\n",
    "    \"\"\"\n",
    "    Given a list of region names and a dataframe with distance information,\n",
    "    this function computes the average distance between all unique pairs.\n",
    "\n",
    "    distances_df should have columns \"Region 1\", \"Region 2\", and \"Normalized Distance\".\n",
    "    \"\"\"\n",
    "    # Generate all unique combinations (pairs) of regions\n",
    "    if len(regions) == 1:\n",
    "        return 0.0\n",
    "    pairs = list(itertools.combinations(regions, 2))\n",
    "    pairs = [pair for pair in pairs if (pair[0] == regions[0] or pair[1] == regions[0])]\n",
    "    distances = []\n",
    "    for r1, r2 in pairs:\n",
    "        print(r1, r2)\n",
    "        # Filter for rows where the pair (in any order) matches r1 and r2.\n",
    "        mask = (((distances_df[\"Region 1\"] == r1) & (distances_df[\"Region 2\"] == r2)) |\n",
    "                ((distances_df[\"Region 1\"] == r2) & (distances_df[\"Region 2\"] == r1)))\n",
    "        \n",
    "        row = distances_df.loc[mask]\n",
    "        if not row.empty:\n",
    "            # Assumes one row per unique pair.\n",
    "            distance = row.iloc[0][column]\n",
    "            distances.append(distance)\n",
    "    \n",
    "    # Check if any matches were found; if not, return None (or you can raise an error)\n",
    "    if distances:\n",
    "        return sum(distances) / len(distances)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regions: ['CAPITL']\n",
      "Average distance: 0.0\n",
      "\n",
      "CAPITL MHK VL\n",
      "CAPITL NORTH\n",
      "Regions: ['CAPITL', 'MHK VL', 'NORTH']\n",
      "Average distance: 0.5919577291673273\n",
      "\n",
      "CAPITL CENTRL\n",
      "CAPITL HUD VL\n",
      "CAPITL MHK VL\n",
      "CAPITL MILLWD\n",
      "CAPITL NORTH\n",
      "Regions: ['CAPITL', 'CENTRL', 'HUD VL', 'MHK VL', 'MILLWD', 'NORTH']\n",
      "Average distance: 0.9466183041464564\n",
      "\n",
      "CAPITL CENTRL\n",
      "CAPITL GENESE\n",
      "CAPITL HUD VL\n",
      "CAPITL LONGIL\n",
      "CAPITL MHK VL\n",
      "CAPITL MILLWD\n",
      "CAPITL NORTH\n",
      "CAPITL WEST\n",
      "Regions: ['CAPITL', 'CENTRL', 'GENESE', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'NORTH', 'WEST']\n",
      "Average distance: 1.2452250995593415\n",
      "\n",
      "CAPITL CENTRL\n",
      "CAPITL DUNWOD\n",
      "CAPITL GENESE\n",
      "CAPITL HUD VL\n",
      "CAPITL LONGIL\n",
      "CAPITL MHK VL\n",
      "CAPITL MILLWD\n",
      "CAPITL N.Y.C.\n",
      "CAPITL NORTH\n",
      "CAPITL WEST\n",
      "Regions: ['CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'N.Y.C.', 'NORTH', 'WEST']\n",
      "Average distance: 1.380337081798436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subset_captil = ['CAPITL', 'CAPITL_MHK VL_NORTH', 'CAPITL_CENTRL_HUD VL_MHK VL_MILLWD_NORTH', 'CAPITL_CENTRL_GENESE_HUD VL_LONGIL_MHK VL_MILLWD_NORTH_WEST', 'CAPITL_CENTRL_DUNWOD_GENESE_HUD VL_LONGIL_MHK VL_MILLWD_N.Y.C._NORTH_WEST']\n",
    "\n",
    "for subset in subset_captil:\n",
    "    # Split the string at \"_\" to infer individual regions\n",
    "    regions = subset.split(\"_\")\n",
    "    avg_dist = average_distance_between_regions(regions, distances_df)\n",
    "    print(f\"Regions: {regions}\\nAverage distance: {avg_dist}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average distance: 134.19151078096544\n",
      "Average distance: 214.51058674685788\n",
      "Average distance: 263.2697326129474\n",
      "Average distance: 256.95182056406793\n"
     ]
    }
   ],
   "source": [
    "subset_captil = ['CAPITL', 'CAPITL_MHK VL_NORTH', 'CAPITL_CENTRL_HUD VL_MHK VL_MILLWD_NORTH', 'CAPITL_CENTRL_GENESE_HUD VL_LONGIL_MHK VL_MILLWD_NORTH_WEST', 'CAPITL_CENTRL_DUNWOD_GENESE_HUD VL_LONGIL_MHK VL_MILLWD_N.Y.C._NORTH_WEST']\n",
    "\n",
    "for subset in subset_captil:\n",
    "    print(f\"Average distance: {average_distance_between_regions(subset.split('_'), distances_df, 'Physical Distance (km)')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CENTRL_GENESE_WEST','CAPITL_CENTRL_GENESE_HUD VL_MHK VL_WEST','CAPITL_CENTRL_GENESE_HUD VL_LONGIL_MHK VL_N.Y.C._NORTH_WEST','CAPITL_CENTRL_DUNWOD_GENESE_HUD VL_LONGIL_MHK VL_MILLWD_N.Y.C._NORTH_WEST',]"
     ]
    }
   ],
   "source": [
    "d = closest_locations(distances_df, 'Region 1', 'Region 2', 'Normalized Distance', 3)\n",
    "\n",
    "print('[', end='')\n",
    "for l in d['WEST']:\n",
    "    l.sort()\n",
    "    print(\"'\", end='')\n",
    "    print('_'.join(l), end='')\n",
    "    print(\"',\", end='')\n",
    "print(']', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CAPITL': [['CAPITL', 'MHK VL', 'NORTH'],\n",
       "  ['CAPITL', 'MHK VL', 'NORTH', 'HUD VL', 'CENTRL', 'MILLWD'],\n",
       "  ['CAPITL',\n",
       "   'MHK VL',\n",
       "   'NORTH',\n",
       "   'HUD VL',\n",
       "   'CENTRL',\n",
       "   'MILLWD',\n",
       "   'GENESE',\n",
       "   'LONGIL',\n",
       "   'WEST'],\n",
       "  ['CAPITL',\n",
       "   'MHK VL',\n",
       "   'NORTH',\n",
       "   'HUD VL',\n",
       "   'CENTRL',\n",
       "   'MILLWD',\n",
       "   'GENESE',\n",
       "   'LONGIL',\n",
       "   'WEST',\n",
       "   'DUNWOD',\n",
       "   'N.Y.C.']],\n",
       " 'CENTRL': [['CENTRL', 'GENESE', 'MHK VL'],\n",
       "  ['CENTRL', 'GENESE', 'MHK VL', 'WEST', 'CAPITL', 'HUD VL'],\n",
       "  ['CENTRL',\n",
       "   'GENESE',\n",
       "   'MHK VL',\n",
       "   'WEST',\n",
       "   'CAPITL',\n",
       "   'HUD VL',\n",
       "   'NORTH',\n",
       "   'MILLWD',\n",
       "   'DUNWOD'],\n",
       "  ['CENTRL',\n",
       "   'GENESE',\n",
       "   'MHK VL',\n",
       "   'WEST',\n",
       "   'CAPITL',\n",
       "   'HUD VL',\n",
       "   'NORTH',\n",
       "   'MILLWD',\n",
       "   'DUNWOD',\n",
       "   'N.Y.C.',\n",
       "   'LONGIL']],\n",
       " 'MHK VL': [['MHK VL', 'CAPITL', 'CENTRL'],\n",
       "  ['MHK VL', 'CAPITL', 'CENTRL', 'NORTH', 'HUD VL', 'GENESE'],\n",
       "  ['MHK VL',\n",
       "   'CAPITL',\n",
       "   'CENTRL',\n",
       "   'NORTH',\n",
       "   'HUD VL',\n",
       "   'GENESE',\n",
       "   'WEST',\n",
       "   'MILLWD',\n",
       "   'DUNWOD'],\n",
       "  ['MHK VL',\n",
       "   'CAPITL',\n",
       "   'CENTRL',\n",
       "   'NORTH',\n",
       "   'HUD VL',\n",
       "   'GENESE',\n",
       "   'WEST',\n",
       "   'MILLWD',\n",
       "   'DUNWOD',\n",
       "   'LONGIL',\n",
       "   'N.Y.C.']],\n",
       " 'HUD VL': [['HUD VL', 'MILLWD', 'DUNWOD'],\n",
       "  ['HUD VL', 'MILLWD', 'DUNWOD', 'CAPITL', 'MHK VL', 'LONGIL'],\n",
       "  ['HUD VL',\n",
       "   'MILLWD',\n",
       "   'DUNWOD',\n",
       "   'CAPITL',\n",
       "   'MHK VL',\n",
       "   'LONGIL',\n",
       "   'N.Y.C.',\n",
       "   'CENTRL',\n",
       "   'NORTH'],\n",
       "  ['HUD VL',\n",
       "   'MILLWD',\n",
       "   'DUNWOD',\n",
       "   'CAPITL',\n",
       "   'MHK VL',\n",
       "   'LONGIL',\n",
       "   'N.Y.C.',\n",
       "   'CENTRL',\n",
       "   'NORTH',\n",
       "   'WEST',\n",
       "   'GENESE']],\n",
       " 'LONGIL': [['LONGIL', 'HUD VL', 'DUNWOD'],\n",
       "  ['LONGIL', 'HUD VL', 'DUNWOD', 'N.Y.C.', 'MILLWD', 'MHK VL'],\n",
       "  ['LONGIL',\n",
       "   'HUD VL',\n",
       "   'DUNWOD',\n",
       "   'N.Y.C.',\n",
       "   'MILLWD',\n",
       "   'MHK VL',\n",
       "   'CAPITL',\n",
       "   'CENTRL',\n",
       "   'WEST'],\n",
       "  ['LONGIL',\n",
       "   'HUD VL',\n",
       "   'DUNWOD',\n",
       "   'N.Y.C.',\n",
       "   'MILLWD',\n",
       "   'MHK VL',\n",
       "   'CAPITL',\n",
       "   'CENTRL',\n",
       "   'WEST',\n",
       "   'NORTH',\n",
       "   'GENESE']],\n",
       " 'N.Y.C.': [['N.Y.C.', 'DUNWOD', 'HUD VL'],\n",
       "  ['N.Y.C.', 'DUNWOD', 'HUD VL', 'LONGIL', 'MILLWD', 'MHK VL'],\n",
       "  ['N.Y.C.',\n",
       "   'DUNWOD',\n",
       "   'HUD VL',\n",
       "   'LONGIL',\n",
       "   'MILLWD',\n",
       "   'MHK VL',\n",
       "   'CAPITL',\n",
       "   'CENTRL',\n",
       "   'WEST'],\n",
       "  ['N.Y.C.',\n",
       "   'DUNWOD',\n",
       "   'HUD VL',\n",
       "   'LONGIL',\n",
       "   'MILLWD',\n",
       "   'MHK VL',\n",
       "   'CAPITL',\n",
       "   'CENTRL',\n",
       "   'WEST',\n",
       "   'NORTH',\n",
       "   'GENESE']],\n",
       " 'WEST': [['WEST', 'GENESE', 'CENTRL'],\n",
       "  ['WEST', 'GENESE', 'CENTRL', 'MHK VL', 'CAPITL', 'HUD VL'],\n",
       "  ['WEST',\n",
       "   'GENESE',\n",
       "   'CENTRL',\n",
       "   'MHK VL',\n",
       "   'CAPITL',\n",
       "   'HUD VL',\n",
       "   'NORTH',\n",
       "   'LONGIL',\n",
       "   'N.Y.C.'],\n",
       "  ['WEST',\n",
       "   'GENESE',\n",
       "   'CENTRL',\n",
       "   'MHK VL',\n",
       "   'CAPITL',\n",
       "   'HUD VL',\n",
       "   'NORTH',\n",
       "   'LONGIL',\n",
       "   'N.Y.C.',\n",
       "   'MILLWD',\n",
       "   'DUNWOD']],\n",
       " 'GENESE': [['GENESE', 'CENTRL', 'WEST'],\n",
       "  ['GENESE', 'CENTRL', 'WEST', 'MHK VL', 'CAPITL', 'HUD VL'],\n",
       "  ['GENESE',\n",
       "   'CENTRL',\n",
       "   'WEST',\n",
       "   'MHK VL',\n",
       "   'CAPITL',\n",
       "   'HUD VL',\n",
       "   'NORTH',\n",
       "   'LONGIL',\n",
       "   'N.Y.C.'],\n",
       "  ['GENESE',\n",
       "   'CENTRL',\n",
       "   'WEST',\n",
       "   'MHK VL',\n",
       "   'CAPITL',\n",
       "   'HUD VL',\n",
       "   'NORTH',\n",
       "   'LONGIL',\n",
       "   'N.Y.C.',\n",
       "   'MILLWD',\n",
       "   'DUNWOD']],\n",
       " 'NORTH': [['NORTH', 'MHK VL', 'CAPITL'],\n",
       "  ['NORTH', 'MHK VL', 'CAPITL', 'CENTRL', 'HUD VL', 'WEST'],\n",
       "  ['NORTH',\n",
       "   'MHK VL',\n",
       "   'CAPITL',\n",
       "   'CENTRL',\n",
       "   'HUD VL',\n",
       "   'WEST',\n",
       "   'GENESE',\n",
       "   'LONGIL',\n",
       "   'MILLWD'],\n",
       "  ['NORTH',\n",
       "   'MHK VL',\n",
       "   'CAPITL',\n",
       "   'CENTRL',\n",
       "   'HUD VL',\n",
       "   'WEST',\n",
       "   'GENESE',\n",
       "   'LONGIL',\n",
       "   'MILLWD',\n",
       "   'DUNWOD',\n",
       "   'N.Y.C.']],\n",
       " 'DUNWOD': [['DUNWOD', 'MILLWD', 'HUD VL'],\n",
       "  ['DUNWOD', 'MILLWD', 'HUD VL', 'N.Y.C.', 'LONGIL', 'MHK VL'],\n",
       "  ['DUNWOD',\n",
       "   'MILLWD',\n",
       "   'HUD VL',\n",
       "   'N.Y.C.',\n",
       "   'LONGIL',\n",
       "   'MHK VL',\n",
       "   'CAPITL',\n",
       "   'CENTRL',\n",
       "   'WEST'],\n",
       "  ['DUNWOD',\n",
       "   'MILLWD',\n",
       "   'HUD VL',\n",
       "   'N.Y.C.',\n",
       "   'LONGIL',\n",
       "   'MHK VL',\n",
       "   'CAPITL',\n",
       "   'CENTRL',\n",
       "   'WEST',\n",
       "   'NORTH',\n",
       "   'GENESE']],\n",
       " 'MILLWD': [['MILLWD', 'HUD VL', 'DUNWOD'],\n",
       "  ['MILLWD', 'HUD VL', 'DUNWOD', 'LONGIL', 'MHK VL', 'N.Y.C.'],\n",
       "  ['MILLWD',\n",
       "   'HUD VL',\n",
       "   'DUNWOD',\n",
       "   'LONGIL',\n",
       "   'MHK VL',\n",
       "   'N.Y.C.',\n",
       "   'CAPITL',\n",
       "   'CENTRL',\n",
       "   'WEST'],\n",
       "  ['MILLWD',\n",
       "   'HUD VL',\n",
       "   'DUNWOD',\n",
       "   'LONGIL',\n",
       "   'MHK VL',\n",
       "   'N.Y.C.',\n",
       "   'CAPITL',\n",
       "   'CENTRL',\n",
       "   'WEST',\n",
       "   'NORTH',\n",
       "   'GENESE']]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_locations(distances_df, 'Region 1', 'Region 2', 'Normalized Distance', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_subsets(closest_locations(distances_df, 'Region 1', 'Region 2', 'Normalized Distance', 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_subsets = unique_subsets(closest_locations(distances_df, 'Region 1', 'Region 2', 'Normalized Distance', 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(region_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CAPITL', 'CENTRL', 'MHK VL'],\n",
       " ['CENTRL', 'GENESE', 'WEST'],\n",
       " ['DUNWOD', 'HUD VL', 'LONGIL'],\n",
       " ['CENTRL', 'GENESE', 'MHK VL'],\n",
       " ['CAPITL', 'MHK VL', 'NORTH'],\n",
       " ['DUNWOD', 'HUD VL', 'MILLWD'],\n",
       " ['DUNWOD', 'HUD VL', 'N.Y.C.'],\n",
       " ['DUNWOD', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'N.Y.C.'],\n",
       " ['CAPITL', 'DUNWOD', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD'],\n",
       " ['CAPITL', 'CENTRL', 'GENESE', 'HUD VL', 'MHK VL', 'WEST'],\n",
       " ['CAPITL', 'CENTRL', 'HUD VL', 'MHK VL', 'MILLWD', 'NORTH'],\n",
       " ['CAPITL', 'CENTRL', 'GENESE', 'HUD VL', 'MHK VL', 'NORTH'],\n",
       " ['CAPITL', 'CENTRL', 'HUD VL', 'MHK VL', 'NORTH', 'WEST'],\n",
       " ['CAPITL',\n",
       "  'CENTRL',\n",
       "  'DUNWOD',\n",
       "  'HUD VL',\n",
       "  'LONGIL',\n",
       "  'MHK VL',\n",
       "  'MILLWD',\n",
       "  'N.Y.C.',\n",
       "  'WEST'],\n",
       " ['CAPITL',\n",
       "  'CENTRL',\n",
       "  'DUNWOD',\n",
       "  'HUD VL',\n",
       "  'LONGIL',\n",
       "  'MHK VL',\n",
       "  'MILLWD',\n",
       "  'N.Y.C.',\n",
       "  'NORTH'],\n",
       " ['CAPITL',\n",
       "  'CENTRL',\n",
       "  'GENESE',\n",
       "  'HUD VL',\n",
       "  'LONGIL',\n",
       "  'MHK VL',\n",
       "  'MILLWD',\n",
       "  'NORTH',\n",
       "  'WEST'],\n",
       " ['CAPITL',\n",
       "  'CENTRL',\n",
       "  'GENESE',\n",
       "  'HUD VL',\n",
       "  'LONGIL',\n",
       "  'MHK VL',\n",
       "  'N.Y.C.',\n",
       "  'NORTH',\n",
       "  'WEST'],\n",
       " ['CAPITL',\n",
       "  'CENTRL',\n",
       "  'DUNWOD',\n",
       "  'GENESE',\n",
       "  'HUD VL',\n",
       "  'MHK VL',\n",
       "  'MILLWD',\n",
       "  'NORTH',\n",
       "  'WEST'],\n",
       " ['CAPITL',\n",
       "  'CENTRL',\n",
       "  'DUNWOD',\n",
       "  'GENESE',\n",
       "  'HUD VL',\n",
       "  'LONGIL',\n",
       "  'MHK VL',\n",
       "  'MILLWD',\n",
       "  'N.Y.C.',\n",
       "  'NORTH',\n",
       "  'WEST']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CAPITL', 'CENTRL', 'MHK VL']\n",
      "['DUNWOD', 'HUD VL', 'N.Y.C.']\n",
      "['DUNWOD', 'HUD VL', 'MILLWD']\n",
      "['CENTRL', 'GENESE', 'MHK VL']\n",
      "['CAPITL', 'MHK VL', 'NORTH']\n",
      "['DUNWOD', 'HUD VL', 'LONGIL']\n",
      "['CENTRL', 'GENESE', 'WEST']\n",
      "['CAPITL', 'CENTRL', 'HUD VL', 'MHK VL', 'MILLWD', 'NORTH']\n",
      "['DUNWOD', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'N.Y.C.']\n",
      "['CAPITL', 'DUNWOD', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD']\n",
      "['CAPITL', 'CENTRL', 'GENESE', 'HUD VL', 'MHK VL', 'NORTH']\n",
      "['CAPITL', 'CENTRL', 'HUD VL', 'MHK VL', 'NORTH', 'WEST']\n",
      "['CAPITL', 'CENTRL', 'GENESE', 'HUD VL', 'MHK VL', 'WEST']\n",
      "['CAPITL', 'CENTRL', 'DUNWOD', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'N.Y.C.', 'NORTH']\n",
      "['CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD VL', 'MHK VL', 'MILLWD', 'NORTH', 'WEST']\n",
      "['CAPITL', 'CENTRL', 'GENESE', 'HUD VL', 'LONGIL', 'MHK VL', 'N.Y.C.', 'NORTH', 'WEST']\n",
      "['CAPITL', 'CENTRL', 'DUNWOD', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'N.Y.C.', 'WEST']\n",
      "['CAPITL', 'CENTRL', 'GENESE', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'NORTH', 'WEST']\n",
      "['CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'N.Y.C.', 'NORTH', 'WEST']\n"
     ]
    }
   ],
   "source": [
    "region_subsets = sorted(region_subsets, key=len)\n",
    "for i in region_subsets:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python \"S:\\\\spatiotemporal-analysis\\\\spacetimeformer-main\\\\spacetimeformer\\\\train.py\" spacetimeformer \"aemo-NSW-QLD-SA-VIC\" --epochs 100 --context_points 360 --target_points 48 --run_name aemo_NSW_QLD_SA_VIC --use_revin --use_seasonal_decomp --l2_coeff 0.0001 --batch_size 32 --base_lr 0.0001 --learning_rate 0.0001 --d_model 100 --d_ff 400 --enc_layers 1 --dec_layers 1 --dropout_emb .1 --dropout_ff .3 --d_qk 30 --d_v 30 --n_heads 10 --patience 10 --data_path \"C:\\\\Users\\\\vm-user\\\\Downloads\\\\All Datasets\\\\All Datasets\\\\aemo\\\\NSW_QLD_SA_VIC.csv\" --test_only --ckpt_path \"C:\\\\Users\\\\vm-user\\\\Downloads\\\\aemo_NSW_QLD_SA_VICepoch=07.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\n",
    "]\n",
    "\n",
    "['CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'N.Y.C.', 'NORTH', 'WEST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct\n",
    "\n",
    "l = [['NSW'],\n",
    " ['TAS'],\n",
    " ['QLD'],\n",
    " ['VIC'],\n",
    " ['SA'],\n",
    " ['NSW', 'QLD'],\n",
    " ['NSW', 'VIC'],\n",
    " ['QLD', 'SA'],\n",
    " ['TAS', 'VIC'],\n",
    " ['NSW', 'SA', 'VIC'],\n",
    " ['NSW', 'QLD', 'VIC'],\n",
    " ['NSW', 'QLD', 'SA'],\n",
    " ['NSW', 'TAS', 'VIC'],\n",
    " ['NSW', 'QLD', 'SA', 'VIC'],\n",
    " ['NSW', 'SA', 'TAS', 'VIC'],\n",
    " ['NSW', 'QLD', 'SA', 'TAS', 'VIC']]\n",
    "\n",
    "\n",
    "CAPITL\n",
    "CENTRL\n",
    "MHK VL\n",
    "HUD VL\n",
    "LONGIL\n",
    "N.Y.C.\n",
    "WEST\n",
    "GENESE\n",
    "NORTH\n",
    "DUNWOD\n",
    "MILLWD\n",
    "['CAPITL', 'CENTRL', 'MHK VL']\n",
    "['DUNWOD', 'HUD VL', 'N.Y.C.']\n",
    "['DUNWOD', 'HUD VL', 'MILLWD']\n",
    "['CENTRL', 'GENESE', 'MHK VL']\n",
    "['CAPITL', 'MHK VL', 'NORTH']\n",
    "['DUNWOD', 'HUD VL', 'LONGIL']\n",
    "['CENTRL', 'GENESE', 'WEST']\n",
    "['CAPITL', 'CENTRL', 'HUD VL', 'MHK VL', 'MILLWD', 'NORTH']\n",
    "['DUNWOD', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'N.Y.C.']\n",
    "['CAPITL', 'DUNWOD', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD']\n",
    "['CAPITL', 'CENTRL', 'GENESE', 'HUD VL', 'MHK VL', 'NORTH']\n",
    "['CAPITL', 'CENTRL', 'HUD VL', 'MHK VL', 'NORTH', 'WEST']\n",
    "['CAPITL', 'CENTRL', 'GENESE', 'HUD VL', 'MHK VL', 'WEST']\n",
    "['CAPITL', 'CENTRL', 'DUNWOD', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'N.Y.C.', 'NORTH']\n",
    "['CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD VL', 'MHK VL', 'MILLWD', 'NORTH', 'WEST']\n",
    "['CAPITL', 'CENTRL', 'GENESE', 'HUD VL', 'LONGIL', 'MHK VL', 'N.Y.C.', 'NORTH', 'WEST']\n",
    "['CAPITL', 'CENTRL', 'DUNWOD', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'N.Y.C.', 'WEST']\n",
    "['CAPITL', 'CENTRL', 'GENESE', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'NORTH', 'WEST']\n",
    "['CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'N.Y.C.', 'NORTH', 'WEST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPITL\n",
      "CENTRL\n",
      "MHK VL\n",
      "HUD VL\n",
      "LONGIL\n",
      "N.Y.C.\n",
      "WEST\n",
      "GENESE\n",
      "NORTH\n",
      "DUNWOD\n",
      "MILLWD\n"
     ]
    }
   ],
   "source": [
    "for region in regions:\n",
    "    print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time Stamp    0\n",
       "CAPITL        0\n",
       "CENTRL        0\n",
       "DUNWOD        0\n",
       "GENESE        0\n",
       "HUD VL        0\n",
       "LONGIL        0\n",
       "MHK VL        0\n",
       "MILLWD        0\n",
       "N.Y.C.        0\n",
       "NORTH         0\n",
       "WEST          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyiso_data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_nyiso(df, selected_columns):\n",
    "    \"\"\"\n",
    "    Filters the given DataFrame to retain only the selected columns, \n",
    "    and removes initial and bottom-most rows where all selected columns are NaN.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "        selected_columns (list): List of column names to retain.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # Ensure 'Datetime (UTC)' is included in the filtered columns\n",
    "    filtered_columns = ['Time Stamp'] + selected_columns if 'Time Stamp' in df.columns else selected_columns\n",
    "    df_filtered = df[filtered_columns]\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CAPITL.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CENTRL.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_MHK VL.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_HUD VL.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_LONGIL.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_N.Y.C..csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_WEST.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_GENESE.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_NORTH.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_DUNWOD.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_MILLWD.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CENTRL_GENESE_WEST.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_DUNWOD_HUD VL_N.Y.C..csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_DUNWOD_HUD VL_LONGIL.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_DUNWOD_HUD VL_MILLWD.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CAPITL_MHK VL_NORTH.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CENTRL_GENESE_MHK VL.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CAPITL_CENTRL_MHK VL.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CAPITL_CENTRL_GENESE_HUD VL_MHK VL_NORTH.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CAPITL_CENTRL_HUD VL_MHK VL_NORTH_WEST.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CAPITL_DUNWOD_HUD VL_LONGIL_MHK VL_MILLWD.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_DUNWOD_HUD VL_LONGIL_MHK VL_MILLWD_N.Y.C..csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CAPITL_CENTRL_GENESE_HUD VL_MHK VL_WEST.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CAPITL_CENTRL_HUD VL_MHK VL_MILLWD_NORTH.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CAPITL_CENTRL_DUNWOD_HUD VL_LONGIL_MHK VL_MILLWD_N.Y.C._NORTH.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CAPITL_CENTRL_DUNWOD_GENESE_HUD VL_MHK VL_MILLWD_NORTH_WEST.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CAPITL_CENTRL_GENESE_HUD VL_LONGIL_MHK VL_MILLWD_NORTH_WEST.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CAPITL_CENTRL_DUNWOD_HUD VL_LONGIL_MHK VL_MILLWD_N.Y.C._WEST.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CAPITL_CENTRL_GENESE_HUD VL_LONGIL_MHK VL_N.Y.C._NORTH_WEST.csv\n",
      "Saved: C:\\Users\\vm-user\\Downloads\\nyiso_CAPITL_CENTRL_DUNWOD_GENESE_HUD VL_LONGIL_MHK VL_MILLWD_N.Y.C._NORTH_WEST.csv\n"
     ]
    }
   ],
   "source": [
    "nyiso_data_df['Time Stamp'] = pd.to_datetime(nyiso_data_df['Time Stamp'])\n",
    "nyiso_data_df['Time Stamp'] = nyiso_data_df['Time Stamp'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "for region in regions:\n",
    "    df_to_save = filter_nyiso(nyiso_data_df, [region])\n",
    "    output_file_path = f\"C:\\\\Users\\\\vm-user\\\\Downloads\\\\nyiso_{region}.csv\"\n",
    "    # Print a message to see if the df has null values\n",
    "    if df_to_save.isnull().values.any():\n",
    "        print(f\"Warning: DataFrame for {region} contains null values.\")\n",
    "\n",
    "    df_to_save.to_csv(output_file_path, index=False)\n",
    "    print(f\"Saved: {output_file_path}\")\n",
    "\n",
    "for subset in region_subsets:\n",
    "    df_to_save = filter_nyiso(nyiso_data_df, subset)\n",
    "    output_file_path = f\"C:\\\\Users\\\\vm-user\\\\Downloads\\\\nyiso_{'_'.join(subset)}.csv\"\n",
    "    # Print a message to see if the df has null values\n",
    "    if df_to_save.isnull().values.any():\n",
    "        print(f\"Warning: DataFrame for {subset} contains null values.\")\n",
    "    df_to_save.to_csv(output_file_path, index=False)\n",
    "    print(f\"Saved: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL\n",
    "\n",
    "nsw_qld_sa_vic_tas = {\n",
    "    \"test/acc\": 0.9999704957008362,\n",
    "    \"test/class_loss\": 0.0018233139999210835,\n",
    "    \"test/forecast_loss\": 2.3405966758728027,\n",
    "    \"test/loss\": 2.340778112411499,\n",
    "    \"test/mae\": 234.49581909179688,\n",
    "    \"test/mape\": 3.645725727081299,\n",
    "    \"test/mse\": 232049.1875,\n",
    "    \"test/norm_mae\": 0.5295851230621338,\n",
    "    \"test/norm_mse\": 2.3405728340148926,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.47333967685699463\n",
    "}\n",
    "\n",
    "nsw = {\n",
    "    \"test/acc\": 0.9999672174453735,\n",
    "    \"test/class_loss\": 0.0005202997126616538,\n",
    "    \"test/forecast_loss\": 3.6325647830963135,\n",
    "    \"test/loss\": 3.6326160430908203,\n",
    "    \"test/mae\": 396.374755859375,\n",
    "    \"test/mape\": 1.3492451906204224,\n",
    "    \"test/mse\": 530329.0,\n",
    "    \"test/norm_mae\": 0.5416648387908936,\n",
    "    \"test/norm_mse\": 3.632528066635132,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.3519725799560547\n",
    "}\n",
    "\n",
    "nsw_qld = {\n",
    "    \"test/acc\": 0.99991375207901,\n",
    "    \"test/class_loss\": 0.0015330464811995625,\n",
    "    \"test/forecast_loss\": 2.8653838634490967,\n",
    "    \"test/loss\": 2.865537643432617,\n",
    "    \"test/mae\": 311.83941650390625,\n",
    "    \"test/mape\": 1.163816213607788,\n",
    "    \"test/mse\": 357305.09375,\n",
    "    \"test/norm_mae\": 0.48017483949661255,\n",
    "    \"test/norm_mse\": 2.86535382270813,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.36608725786209106\n",
    "}\n",
    "\n",
    "# additional\n",
    "nsw_qld_vic_tas = {\n",
    "    \"test/acc\": 0.9996684789657593,\n",
    "    \"test/class_loss\": 0.0025208292063325644,\n",
    "    \"test/forecast_loss\": 2.498936176300049,\n",
    "    \"test/loss\": 2.4991865158081055,\n",
    "    \"test/mae\": 260.812744140625,\n",
    "    \"test/mape\": 3.8596131801605225,\n",
    "    \"test/mse\": 269812.625,\n",
    "    \"test/norm_mae\": 0.5280795097351074,\n",
    "    \"test/norm_mse\": 2.498910903930664,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.42840543389320374\n",
    "}\n",
    "\n",
    "qld = {\n",
    "    \"test/acc\": 0.9999993443489075,\n",
    "    \"test/class_loss\": 4.931714283884503e-05,\n",
    "    \"test/forecast_loss\": 2.4047129154205322,\n",
    "    \"test/loss\": 2.4047179222106934,\n",
    "    \"test/mae\": 308.598876953125,\n",
    "    \"test/mape\": 1.373152494430542,\n",
    "    \"test/mse\": 291895.40625,\n",
    "    \"test/norm_mae\": 0.5714372992515564,\n",
    "    \"test/norm_mse\": 2.4046895503997803,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.41102471947669983\n",
    "}\n",
    "\n",
    "nsw_vic = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 0.00022880075266584754,\n",
    "    \"test/forecast_loss\": 2.2792913913726807,\n",
    "    \"test/loss\": 2.279313564300537,\n",
    "    \"test/mae\": 345.0459899902344,\n",
    "    \"test/mape\": 4.416192054748535,\n",
    "    \"test/mse\": 391612.71875,\n",
    "    \"test/norm_mae\": 0.5041431188583374,\n",
    "    \"test/norm_mse\": 2.279268980026245,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.45057564973831177\n",
    "}\n",
    "\n",
    "nsw_qld_vic = {\n",
    "    \"test/acc\": 0.9987006187438965,\n",
    "    \"test/class_loss\": 0.014215604402124882,\n",
    "    \"test/forecast_loss\": 2.2719411849975586,\n",
    "    \"test/loss\": 2.2733612060546875,\n",
    "    \"test/mae\": 308.4784851074219,\n",
    "    \"test/mape\": 2.0575342178344727,\n",
    "    \"test/mse\": 326476.125,\n",
    "    \"test/norm_mae\": 0.483934611082077,\n",
    "    \"test/norm_mse\": 2.271919012069702,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.45590466260910034\n",
    "}\n",
    "\n",
    "\n",
    "NSW_SA_TAS_VIC = {\n",
    "    'test/acc': 0.999994695186615,\n",
    "    'test/class_loss': 6.406679312931374e-05,\n",
    "    'test/forecast_loss': 2.291043281555176,\n",
    "    'test/loss': 2.2910513877868652,\n",
    "    'test/mae': 226.53167724609375,\n",
    "    'test/mape': 3.820439100265503,\n",
    "    'test/mse': 243321.28125,\n",
    "    'test/norm_mae': 0.5128385424613953,\n",
    "    'test/norm_mse': 2.291020393371582,\n",
    "    'test/recon_loss': -1.0,\n",
    "    'test/smape': 0.5012460947036743\n",
    "}\n",
    "\n",
    "\n",
    "NSW_QLD_SA_VIC = {\n",
    "    'test/acc': 0.9999899864196777,\n",
    "    'test/class_loss': 0.0009756253566592932,\n",
    "    'test/forecast_loss': 2.066863775253296,\n",
    "    'test/loss': 2.0669617652893066,\n",
    "    'test/mae': 262.3127136230469,\n",
    "    'test/mape': 2.3660895824432373,\n",
    "    'test/mse': 264874.1875,\n",
    "    'test/norm_mae': 0.4795970916748047,\n",
    "    'test/norm_mse': 2.0668442249298096,\n",
    "    'test/recon_loss': -1.0,\n",
    "    'test/smape': 0.49104467034339905\n",
    "}\n",
    "\n",
    "\n",
    "NSW_TAS_VIC = {\n",
    "    'test/acc': 0.9999978542327881,\n",
    "    'test/class_loss': 0.00014460313832387328,\n",
    "    'test/forecast_loss': 3.0250966548919678,\n",
    "    'test/loss': 3.025111198425293,\n",
    "    'test/mae': 286.9242248535156,\n",
    "    'test/mape': 10.117528915405273,\n",
    "    'test/mse': 332857.28125,\n",
    "    'test/norm_mae': 0.6201017498970032,\n",
    "    'test/norm_mse': 3.025066375732422,\n",
    "    'test/recon_loss': -1.0,\n",
    "    'test/smape': 0.4419724941253662\n",
    "}\n",
    "\n",
    "\n",
    "NSW_QLD_SA = {\n",
    "    'test/acc': 1.0,\n",
    "    'test/class_loss': 0.0001490989961894229,\n",
    "    'test/forecast_loss': 3.5893325805664062,\n",
    "    'test/loss': 3.5893476009368896,\n",
    "    'test/mae': 353.2463684082031,\n",
    "    'test/mape': 5.304133892059326,\n",
    "    'test/mse': 378415.96875,\n",
    "    'test/norm_mae': 0.8099026679992676,\n",
    "    'test/norm_mse': 3.589296579360962,\n",
    "    'test/recon_loss': -1.0,\n",
    "    'test/smape': 0.5212534666061401\n",
    "}\n",
    "\n",
    "\n",
    "NSW_SA_VIC = {\n",
    "    'test/acc': 0.999920129776001,\n",
    "    'test/class_loss': 0.0036400395911186934,\n",
    "    'test/forecast_loss': 2.0599873065948486,\n",
    "    'test/loss': 2.0603511333465576,\n",
    "    'test/mae': 275.84429931640625,\n",
    "    'test/mape': 4.273866176605225,\n",
    "    'test/mse': 293544.09375,\n",
    "    'test/norm_mae': 0.5130354762077332,\n",
    "    'test/norm_mse': 2.0599663257598877,\n",
    "    'test/recon_loss': -1.0,\n",
    "    'test/smape': 0.5105653405189514\n",
    "}\n",
    "\n",
    "\n",
    "TAS_VIC = {\n",
    "    'test/acc': 0.9999988675117493,\n",
    "    'test/class_loss': 0.00018868206825572997,\n",
    "    'test/forecast_loss': 2.00669002532959,\n",
    "    'test/loss': 2.0067076683044434,\n",
    "    'test/mae': 180.10763549804688,\n",
    "    'test/mape': 9.2027587890625,\n",
    "    'test/mse': 149156.25,\n",
    "    'test/norm_mae': 0.510602593421936,\n",
    "    'test/norm_mse': 2.0066702365875244,\n",
    "    'test/recon_loss': -1.0,\n",
    "    'test/smape': 0.4641474187374115\n",
    "}\n",
    "\n",
    "\n",
    "QLD_SA = {\n",
    "    'test/acc': 1.0,\n",
    "    'test/class_loss': 1.4576493413187563e-05,\n",
    "    'test/forecast_loss': 2.115231513977051,\n",
    "    'test/loss': 2.1152329444885254,\n",
    "    'test/mae': 229.3065185546875,\n",
    "    'test/mape': 3.9114978313446045,\n",
    "    'test/mse': 177347.265625,\n",
    "    'test/norm_mae': 0.6004430651664734,\n",
    "    'test/norm_mse': 2.1152100563049316,\n",
    "    'test/recon_loss': -1.0,\n",
    "    'test/smape': 0.532358705997467\n",
    "}\n",
    "\n",
    "\n",
    "SA = {\n",
    "    'test/acc': 1.0,\n",
    "    'test/class_loss': 1.8859866031561978e-05,\n",
    "    'test/forecast_loss': 1.5413442850112915,\n",
    "    'test/loss': 1.5413461923599243,\n",
    "    'test/mae': 147.66839599609375,\n",
    "    'test/mape': 2.938582181930542,\n",
    "    'test/mse': 110239.5546875,\n",
    "    'test/norm_mae': 0.5044668912887573,\n",
    "    'test/norm_mse': 1.5413289070129395,\n",
    "    'test/recon_loss': -1.0,\n",
    "    'test/smape': 0.6409849524497986\n",
    "}\n",
    "\n",
    "\n",
    "VIC = {\n",
    "    'test/acc': 1.0,\n",
    "    'test/class_loss': 1.4665401977254078e-06,\n",
    "    'test/forecast_loss': 1.0325630903244019,\n",
    "    'test/loss': 1.032563328742981,\n",
    "    'test/mae': 302.2825012207031,\n",
    "    'test/mape': 7.884873867034912,\n",
    "    'test/mse': 292761.34375,\n",
    "    'test/norm_mae': 0.47561830282211304,\n",
    "    'test/norm_mse': 1.0325520038604736,\n",
    "    'test/recon_loss': -1.0,\n",
    "    'test/smape': 0.5565780401229858\n",
    "}\n",
    "\n",
    "TAS = {\n",
    "    'test/acc': 1.0,\n",
    "    'test/class_loss': 8.936825179262087e-05,\n",
    "    'test/forecast_loss': 2.9573781490325928,\n",
    "    'test/loss': 2.9573867321014404,\n",
    "    'test/mae': 55.12985610961914,\n",
    "    'test/mape': 6.255341529846191,\n",
    "    'test/mse': 17400.708984375,\n",
    "    'test/norm_mae': 0.5364540219306946,\n",
    "    'test/norm_mse': 2.9573497772216797,\n",
    "    'test/recon_loss': -1.0,\n",
    "    'test/smape': 0.38621100783348083\n",
    "}\n",
    "\n",
    "\n",
    "DUNWOD_HUD_VL_LONGIL_MHK_VL_MILLWD_NYC = {\n",
    "    \"test/acc\": 0.9999966025352478,\n",
    "    \"test/class_loss\": 0.07700246572494507,\n",
    "    \"test/forecast_loss\": 0.021472575142979622,\n",
    "    \"test/loss\": 0.029172804206609726,\n",
    "    \"test/mae\": 2654.209716796875,\n",
    "    \"test/mape\": 3.225375175476074,\n",
    "    \"test/mse\": 232170704.0,\n",
    "    \"test/norm_mae\": 0.02553042396903038,\n",
    "    \"test/norm_mse\": 0.02147235907614231,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.7266609072685242\n",
    "}\n",
    "\n",
    "HUD_VL = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 0.0,\n",
    "    \"test/forecast_loss\": 0.013604830019176006,\n",
    "    \"test/loss\": 0.013604830019176006,\n",
    "    \"test/mae\": 1503.0147705078125,\n",
    "    \"test/mape\": 1.4490935802459717,\n",
    "    \"test/mse\": 147330368.0,\n",
    "    \"test/norm_mae\": 0.014443130232393742,\n",
    "    \"test/norm_mse\": 0.013604693114757538,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.5379265546798706\n",
    "}\n",
    "\n",
    "MILLWD = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 0.0,\n",
    "    \"test/forecast_loss\": 0.01821964792907238,\n",
    "    \"test/loss\": 0.01821964792907238,\n",
    "    \"test/mae\": 2152.873046875,\n",
    "    \"test/mape\": 6.771895885467529,\n",
    "    \"test/mse\": 197615840.0,\n",
    "    \"test/norm_mae\": 0.020671667531132698,\n",
    "    \"test/norm_mse\": 0.018219463527202606,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 1.4896466732025146\n",
    "}\n",
    "\n",
    "DUNWOD_HUD_VL_LONGIL = {\n",
    "    \"test/acc\": 0.9999963641166687,\n",
    "    \"test/class_loss\": 1.4901997928973287e-05,\n",
    "    \"test/forecast_loss\": 0.01187007687985897,\n",
    "    \"test/loss\": 0.01187157817184925,\n",
    "    \"test/mae\": 1061.2105712890625,\n",
    "    \"test/mape\": 0.9823232889175415,\n",
    "    \"test/mse\": 128470880.0,\n",
    "    \"test/norm_mae\": 0.010201247408986092,\n",
    "    \"test/norm_mse\": 0.011869959533214569,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.42613494396209717\n",
    "}\n",
    "\n",
    "CAPITL_CENTRL_DUNWOD_GENESE_HUD_VL_MHK_VL_MILLWD_NORTH_WEST = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 2.0318542738095857e-05,\n",
    "    \"test/forecast_loss\": 0.01120595820248127,\n",
    "    \"test/loss\": 0.011207984760403633,\n",
    "    \"test/mae\": 832.6868896484375,\n",
    "    \"test/mape\": 0.9222472310066223,\n",
    "    \"test/mse\": 121361912.0,\n",
    "    \"test/norm_mae\": 0.008001520298421383,\n",
    "    \"test/norm_mse\": 0.011205845512449741,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.4380180239677429\n",
    "}\n",
    "\n",
    "CENTRL_GENESE_MHK_VL = {\n",
    "    \"test/acc\": 0.9999998807907104,\n",
    "    \"test/class_loss\": 0.0012411607895046473,\n",
    "    \"test/forecast_loss\": 0.014265650883316994,\n",
    "    \"test/loss\": 0.014389771968126297,\n",
    "    \"test/mae\": 1583.602783203125,\n",
    "    \"test/mape\": 1.3973913192749023,\n",
    "    \"test/mse\": 154432240.0,\n",
    "    \"test/norm_mae\": 0.015220343135297298,\n",
    "    \"test/norm_mse\": 0.014265506528317928,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.5700980424880981\n",
    "}\n",
    "\n",
    "CAPITL_DUNWOD_HUD_VL_LONGIL_MHK_VL_MILLWD = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 0.0003482261090539396,\n",
    "    \"test/forecast_loss\": 0.013380737043917179,\n",
    "    \"test/loss\": 0.013415569439530373,\n",
    "    \"test/mae\": 1614.340087890625,\n",
    "    \"test/mape\": 2.150481700897217,\n",
    "    \"test/mse\": 144900464.0,\n",
    "    \"test/norm_mae\": 0.01551351323723793,\n",
    "    \"test/norm_mse\": 0.013380602933466434,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.6656721830368042\n",
    "}\n",
    "\n",
    "CAPITL_CENTRL_GENESE_HUD_VL_LONGIL_MHK_VL_MILLWD_NORTH_WEST = {\n",
    "    \"test/acc\": 0.9999977350234985,\n",
    "    \"test/class_loss\": 0.00011981472198385745,\n",
    "    \"test/forecast_loss\": 0.017954139038920403,\n",
    "    \"test/loss\": 0.017966115847229958,\n",
    "    \"test/mae\": 1734.356689453125,\n",
    "    \"test/mape\": 1.8922516107559204,\n",
    "    \"test/mse\": 194373824.0,\n",
    "    \"test/norm_mae\": 0.01666896790266037,\n",
    "    \"test/norm_mse\": 0.017953956499695778,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.6376346945762634\n",
    "}\n",
    "\n",
    "CENTRL = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 0.0,\n",
    "    \"test/forecast_loss\": 0.013620934449136257,\n",
    "    \"test/loss\": 0.013620934449136257,\n",
    "    \"test/mae\": 1521.7685546875,\n",
    "    \"test/mape\": 0.8656660914421082,\n",
    "    \"test/mse\": 147293408.0,\n",
    "    \"test/norm_mae\": 0.014633851125836372,\n",
    "    \"test/norm_mse\": 0.013620797544717789,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.4046041667461395\n",
    "}\n",
    "\n",
    "CAPITL_CENTRL_MHK_VL = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 1.652054925216362e-05,\n",
    "    \"test/forecast_loss\": 0.011556754820048809,\n",
    "    \"test/loss\": 0.011558408848941326,\n",
    "    \"test/mae\": 987.944091796875,\n",
    "    \"test/mape\": 0.7865293622016907,\n",
    "    \"test/mse\": 125086568.0,\n",
    "    \"test/norm_mae\": 0.009496129117906094,\n",
    "    \"test/norm_mse\": 0.011556641198694706,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.40760719776153564\n",
    "}\n",
    "\n",
    "NORTH = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 0.0,\n",
    "    \"test/forecast_loss\": 0.01234312355518341,\n",
    "    \"test/loss\": 0.01234312355518341,\n",
    "    \"test/mae\": 1078.2430419921875,\n",
    "    \"test/mape\": 1.4331727027893066,\n",
    "    \"test/mse\": 133822648.0,\n",
    "    \"test/norm_mae\": 0.010355280712246895,\n",
    "    \"test/norm_mse\": 0.012342997826635838,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.5684621930122375\n",
    "}\n",
    "\n",
    "CAPITL_CENTRL_DUNWOD_HUD_VL_LONGIL_MHK_VL_MILLWD_NYC_WEST = {\n",
    "    \"test/acc\": 0.9999963641166687,\n",
    "    \"test/class_loss\": 0.003757036756724119,\n",
    "    \"test/forecast_loss\": 0.01777811534702778,\n",
    "    \"test/loss\": 0.018153807148337364,\n",
    "    \"test/mae\": 2344.9326171875,\n",
    "    \"test/mape\": 2.4068679809570312,\n",
    "    \"test/mse\": 192257952.0,\n",
    "    \"test/norm_mae\": 0.022553149610757828,\n",
    "    \"test/norm_mse\": 0.017777934670448303,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.7284622192382812\n",
    "}\n",
    "\n",
    "CENTRL_GENESE_WEST = {\n",
    "    \"test/acc\": 0.9999991059303284,\n",
    "    \"test/class_loss\": 2.626576679176651e-05,\n",
    "    \"test/forecast_loss\": 0.012804306112229824,\n",
    "    \"test/loss\": 0.012806926853954792,\n",
    "    \"test/mae\": 1905.6837158203125,\n",
    "    \"test/mape\": 1.2399706840515137,\n",
    "    \"test/mse\": 138532912.0,\n",
    "    \"test/norm_mae\": 0.01832132413983345,\n",
    "    \"test/norm_mse\": 0.012804176658391953,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.949256181716919\n",
    "}\n",
    "\n",
    "DUNWOD = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 0.0,\n",
    "    \"test/forecast_loss\": 0.013317253440618515,\n",
    "    \"test/loss\": 0.013317253440618515,\n",
    "    \"test/mae\": 1477.5126953125,\n",
    "    \"test/mape\": 2.3620119094848633,\n",
    "    \"test/mse\": 144338128.0,\n",
    "    \"test/norm_mae\": 0.014192074537277222,\n",
    "    \"test/norm_mse\": 0.01331711933016777,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.5987970232963562\n",
    "}\n",
    "\n",
    "GENESE = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 0.0,\n",
    "    \"test/forecast_loss\": 0.013815858401358128,\n",
    "    \"test/loss\": 0.013815858401358128,\n",
    "    \"test/mae\": 1516.13623046875,\n",
    "    \"test/mape\": 1.3783208131790161,\n",
    "    \"test/mse\": 149611360.0,\n",
    "    \"test/norm_mae\": 0.014569444581866264,\n",
    "    \"test/norm_mse\": 0.013815720565617085,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.573638379573822\n",
    "}\n",
    "\n",
    "MHK_VL = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 0.0,\n",
    "    \"test/forecast_loss\": 0.011379119008779526,\n",
    "    \"test/loss\": 0.011379119008779526,\n",
    "    \"test/mae\": 899.8667602539062,\n",
    "    \"test/mape\": 0.9958378672599792,\n",
    "    \"test/mse\": 123279552.0,\n",
    "    \"test/norm_mae\": 0.008645396679639816,\n",
    "    \"test/norm_mse\": 0.011379003524780273,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.5659889578819275\n",
    "}\n",
    "\n",
    "LONGIL = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 0.0,\n",
    "    \"test/forecast_loss\": 0.013490378856658936,\n",
    "    \"test/loss\": 0.013490378856658936,\n",
    "    \"test/mae\": 1814.9346923828125,\n",
    "    \"test/mape\": 0.833392858505249,\n",
    "    \"test/mse\": 145718096.0,\n",
    "    \"test/norm_mae\": 0.017462806776165962,\n",
    "    \"test/norm_mse\": 0.013490242883563042,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.47276484966278076\n",
    "}\n",
    "\n",
    "# DUNWOD_HUD_VL_NYC = {\n",
    "#     \"test/acc\": 1.0,\n",
    "#     \"test/class_loss\": 1.839381548052188e-05,\n",
    "#     \"test/forecast_loss\": 0.011135506443679333,\n",
    "#     \"test/loss\": 0.011137349531054497,\n",
    "#     \"test/mae\": 854.00439453125,\n",
    "#     \"test/mape\": 0.5639990568161011,\n",
    "#     \"test/mse\": 120240672.0,\n",
    "#     \"test/norm_mae\": 0.008225065656006336,\n",
    "#     \"test/norm_mse\": 0.011135395616292953,\n",
    "#     \"test/recon_loss\": -1.0,\n",
    "#     \"test/smape\": 0.3226090669631958\n",
    "# }\n",
    "\n",
    "\n",
    "CAPITL_CENTRL_HUD_VL_MHK_VL_MILLWD_NORTH = {\n",
    "    'test/acc': 0.9999864101409912,\n",
    "    'test/class_loss': 0.010778824798762798,\n",
    "    'test/forecast_loss': 0.014716076664626598,\n",
    "    'test/loss': 0.015793945640325546,\n",
    "    'test/mae': 2179.978271484375,\n",
    "    'test/mape': 2.9163126945495605,\n",
    "    'test/mse': 159396368.0,\n",
    "    'test/norm_mae': 0.02094651758670807,\n",
    "    'test/norm_mse': 0.014715931378304958,\n",
    "    'test/recon_loss': -1.0,\n",
    "    'test/smape': 1.063554048538208\n",
    "}\n",
    "\n",
    "CAPITL_CENTRL_HUD_VL_MHK_VL_NORTH_WEST = {\n",
    "    'test/acc': 0.9999991059303284,\n",
    "    'test/class_loss': 0.0015631072456017137,\n",
    "    'test/forecast_loss': 0.011304641142487526,\n",
    "    'test/loss': 0.01146094873547554,\n",
    "    'test/mae': 968.8771362304688,\n",
    "    'test/mape': 0.8284134864807129,\n",
    "    'test/mse': 122387320.0,\n",
    "    'test/norm_mae': 0.009311743080615997,\n",
    "    'test/norm_mse': 0.011304525658488274,\n",
    "    'test/recon_loss': -1.0,\n",
    "    'test/smape': 0.5097997784614563\n",
    "}\n",
    "\n",
    "CAPITL_CENTRL_GENESE_HUD_VL_LONGIL_MHK_VL_N_Y_C_NORTH_WEST = {\n",
    "    'test/acc': 0.9999706149101257,\n",
    "    'test/class_loss': 0.11852862685918808,\n",
    "    'test/forecast_loss': 0.04212141036987305,\n",
    "    'test/loss': 0.05397427827119827,\n",
    "    'test/mae': 4350.669921875,\n",
    "    'test/mape': 3.4397659301757812,\n",
    "    'test/mse': 455451456.0,\n",
    "    'test/norm_mae': 0.041844308376312256,\n",
    "    'test/norm_mse': 0.04212099313735962,\n",
    "    'test/recon_loss': -1.0,\n",
    "    'test/smape': 0.6992670297622681\n",
    "}\n",
    "\n",
    "CAPITL_MHK_VL_NORTH = {\n",
    "    'test/acc': 1.0,\n",
    "    'test/class_loss': 0.00019870027608703822,\n",
    "    'test/forecast_loss': 0.013347466476261616,\n",
    "    'test/loss': 0.013367335312068462,\n",
    "    'test/mae': 1444.9425048828125,\n",
    "    'test/mape': 1.5808160305023193,\n",
    "    'test/mse': 144593536.0,\n",
    "    'test/norm_mae': 0.013882777653634548,\n",
    "    'test/norm_mse': 0.013347333297133446,\n",
    "    'test/recon_loss': -1.0,\n",
    "    'test/smape': 0.4336577355861664\n",
    "}\n",
    "\n",
    "DUNWOD_HUD_VL_NYC = {\n",
    "    'test/acc': 1.0,\n",
    "    'test/class_loss': 0.0002024953719228506,\n",
    "    'test/forecast_loss': 0.013183911330997944,\n",
    "    'test/loss': 0.013204153627157211,\n",
    "    'test/mae': 1971.34765625,\n",
    "    'test/mape': 1.5254237651824951,\n",
    "    'test/mse': 142351952.0,\n",
    "    'test/norm_mae': 0.018982021138072014,\n",
    "    'test/norm_mse': 0.013183780014514923,\n",
    "    'test/recon_loss': -1.0,\n",
    "    'test/smape': 0.7006605863571167\n",
    "}\n",
    "\n",
    "capitl_central_genese_hud_vl_mhk_vl_west = {\n",
    "    \"test/acc\": 0.9999968409538269,\n",
    "    \"test/class_loss\": 0.00801069661974907,\n",
    "    \"test/forecast_loss\": 0.01616775617003441,\n",
    "    \"test/loss\": 0.016968831419944763,\n",
    "    \"test/mae\": 1763.18505859375,\n",
    "    \"test/mape\": 1.4713650941848755,\n",
    "    \"test/mse\": 175001824.0,\n",
    "    \"test/norm_mae\": 0.01694730669260025,\n",
    "    \"test/norm_mse\": 0.016167595982551575,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.4401610493659973\n",
    "}\n",
    "\n",
    "capitl_central_genese_hud_vl_mhk_vl_north = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 0.0034146199468523264,\n",
    "    \"test/forecast_loss\": 0.020248474553227425,\n",
    "    \"test/loss\": 0.02058991976082325,\n",
    "    \"test/mae\": 2349.443359375,\n",
    "    \"test/mape\": 2.336817979812622,\n",
    "    \"test/mse\": 219263920.0,\n",
    "    \"test/norm_mae\": 0.022577621042728424,\n",
    "    \"test/norm_mse\": 0.02024826779961586,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.6717438697814941\n",
    "}\n",
    "\n",
    "capitl = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 0.0,\n",
    "    \"test/forecast_loss\": 0.012773863039910793,\n",
    "    \"test/loss\": 0.012773863039910793,\n",
    "    \"test/mae\": 1342.3072509765625,\n",
    "    \"test/mape\": 1.0298148393630981,\n",
    "    \"test/mse\": 138257024.0,\n",
    "    \"test/norm_mae\": 0.012902302667498589,\n",
    "    \"test/norm_mse\": 0.012773734517395496,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.4512978196144104\n",
    "}\n",
    "\n",
    "nyc = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 0.0,\n",
    "    \"test/forecast_loss\": 0.012484879232943058,\n",
    "    \"test/loss\": 0.012484879232943058,\n",
    "    \"test/mae\": 1829.7938232421875,\n",
    "    \"test/mape\": 0.3260555863380432,\n",
    "    \"test/mse\": 133915224.0,\n",
    "    \"test/norm_mae\": 0.01766757294535637,\n",
    "    \"test/norm_mse\": 0.012484756298363209,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.23400260508060455\n",
    "}\n",
    "\n",
    "capitl_central_dunwod_hud_vl_longil_mhk_vl_millwd_nyc_north = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 3.023819772351999e-05,\n",
    "    \"test/forecast_loss\": 0.01212690956890583,\n",
    "    \"test/loss\": 0.01212993822991848,\n",
    "    \"test/mae\": 1242.4144287109375,\n",
    "    \"test/mape\": 1.265241026878357,\n",
    "    \"test/mse\": 131175568.0,\n",
    "    \"test/norm_mae\": 0.011949179694056511,\n",
    "    \"test/norm_mse\": 0.01212678849697113,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.5249022841453552\n",
    "}\n",
    "\n",
    "west = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 0.0,\n",
    "    \"test/forecast_loss\": 0.017124835401773453,\n",
    "    \"test/loss\": 0.017124835401773453,\n",
    "    \"test/mae\": 2293.335693359375,\n",
    "    \"test/mape\": 1.2933769226074219,\n",
    "    \"test/mse\": 185212224.0,\n",
    "    \"test/norm_mae\": 0.022051796317100525,\n",
    "    \"test/norm_mse\": 0.017124664038419724,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.5141408443450928\n",
    "}\n",
    "\n",
    "dunwod_hud_vl_millwd = {\n",
    "    \"test/acc\": 1.0,\n",
    "    \"test/class_loss\": 0.00012867109035141766,\n",
    "    \"test/forecast_loss\": 0.011324509978294373,\n",
    "    \"test/loss\": 0.011337372474372387,\n",
    "    \"test/mae\": 843.9257202148438,\n",
    "    \"test/mape\": 1.461225986480713,\n",
    "    \"test/mse\": 122734944.0,\n",
    "    \"test/norm_mae\": 0.008106506429612637,\n",
    "    \"test/norm_mse\": 0.01132439635694027,\n",
    "    \"test/recon_loss\": -1.0,\n",
    "    \"test/smape\": 0.7292196750640869\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correct_nyiso_dict(regions_list):\n",
    "    if set(regions_list) == set(['DUNWOD', 'HUD_VL', 'LONGIL', 'MHK_VL', 'MILLWD', 'NYC']):\n",
    "        return DUNWOD_HUD_VL_LONGIL_MHK_VL_MILLWD_NYC\n",
    "    elif set(regions_list) == set(['HUD_VL']):\n",
    "        return HUD_VL\n",
    "    elif set(regions_list) == set(['MILLWD']):\n",
    "        return MILLWD\n",
    "    elif set(regions_list) == set(['DUNWOD', 'HUD_VL', 'LONGIL']):\n",
    "        return DUNWOD_HUD_VL_LONGIL\n",
    "    elif set(regions_list) == set(['CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD_VL', 'MHK_VL', 'MILLWD', 'NORTH', 'WEST']):\n",
    "        return CAPITL_CENTRL_DUNWOD_GENESE_HUD_VL_MHK_VL_MILLWD_NORTH_WEST\n",
    "    elif set(regions_list) == set(['CENTRL', 'GENESE', 'MHK_VL']):\n",
    "        return CENTRL_GENESE_MHK_VL\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive('spacetimeformer', 'zip', '/kaggle/working/spacetimeformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to the zip file\n",
    "zip_file_path = '/kaggle/working/spacetimeformer.zip'\n",
    "\n",
    "# Delete the file\n",
    "if os.path.exists(zip_file_path):\n",
    "    os.remove(zip_file_path)\n",
    "    print(f\"File {zip_file_path} has been deleted.\")\n",
    "else:\n",
    "    print(f\"The file {zip_file_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct\n",
    "\n",
    "l = [\n",
    " ['TAS'],\n",
    " ['VIC'],\n",
    " ['SA'],\n",
    " ['QLD', 'SA'],\n",
    " ['TAS', 'VIC'],\n",
    " ['NSW', 'SA', 'VIC'],\n",
    " ['NSW', 'QLD', 'SA'],\n",
    " ['NSW', 'TAS', 'VIC'],\n",
    " ['NSW', 'QLD', 'SA', 'VIC'],\n",
    " ['NSW', 'SA', 'TAS', 'VIC']\n",
    "]\n",
    "\n",
    "CAPITL\n",
    "CENTRL\n",
    "MHK VL\n",
    "HUD VL\n",
    "LONGIL\n",
    "N.Y.C.\n",
    "WEST\n",
    "GENESE\n",
    "NORTH\n",
    "DUNWOD\n",
    "MILLWD\n",
    "['CAPITL', 'CENTRL', 'MHK VL']\n",
    "['DUNWOD', 'HUD VL', 'N.Y.C.']\n",
    "['DUNWOD', 'HUD VL', 'MILLWD']\n",
    "['CENTRL', 'GENESE', 'MHK VL']\n",
    "['CAPITL', 'MHK VL', 'NORTH']\n",
    "['DUNWOD', 'HUD VL', 'LONGIL']\n",
    "['CENTRL', 'GENESE', 'WEST']\n",
    "['CAPITL', 'CENTRL', 'HUD VL', 'MHK VL', 'MILLWD', 'NORTH']\n",
    "['DUNWOD', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'N.Y.C.']\n",
    "['CAPITL', 'DUNWOD', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD']\n",
    "['CAPITL', 'CENTRL', 'GENESE', 'HUD VL', 'MHK VL', 'NORTH']\n",
    "['CAPITL', 'CENTRL', 'HUD VL', 'MHK VL', 'NORTH', 'WEST']\n",
    "['CAPITL', 'CENTRL', 'GENESE', 'HUD VL', 'MHK VL', 'WEST']\n",
    "['CAPITL', 'CENTRL', 'DUNWOD', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'N.Y.C.', 'NORTH']\n",
    "['CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD VL', 'MHK VL', 'MILLWD', 'NORTH', 'WEST']\n",
    "['CAPITL', 'CENTRL', 'GENESE', 'HUD VL', 'LONGIL', 'MHK VL', 'N.Y.C.', 'NORTH', 'WEST']\n",
    "['CAPITL', 'CENTRL', 'DUNWOD', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'N.Y.C.', 'WEST']\n",
    "['CAPITL', 'CENTRL', 'GENESE', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'NORTH', 'WEST']\n",
    "['CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD VL', 'LONGIL', 'MHK VL', 'MILLWD', 'N.Y.C.', 'NORTH', 'WEST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_dataframe_by_year(file_path: str, time_col: str, start_year: int, end_year: int, new_file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Reads a CSV file, filters rows where the year from time_col is between start_year and end_year (inclusive),\n",
    "    and saves the resulting subset to new_file_path.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the input CSV file.\n",
    "        time_col (str): Name of the column containing date/time values.\n",
    "        start_year (int): Start year (inclusive) for filtering.\n",
    "        end_year (int): End year (inclusive) for filtering.\n",
    "        new_file_path (str): Path to save the filtered CSV.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert the time column to datetime\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "    \n",
    "    # Filter rows where the year is between start_year and end_year\n",
    "    subset = df[(df[time_col].dt.year >= start_year) & (df[time_col].dt.year <= end_year)]\n",
    "\n",
    "    subset[time_col] = subset[time_col].dt.strftime(\"%Y-%m-%d %H:%M\")\n",
    "    \n",
    "    # Save the subset to the new file path\n",
    "    subset.to_csv(new_file_path, index=False)\n",
    "    print(f\"Subset of data from {start_year} to {end_year} saved to {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vm-user\\AppData\\Local\\Temp\\ipykernel_7916\\3140997336.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset[time_col] = subset[time_col].dt.strftime(\"%Y-%m-%d %H:%M\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset of data from 2020 to 2025 saved to C:\\Users\\vm-user\\Downloads\\dynamic\\NSW_QLD_SA_TAS_VIC.csv\n"
     ]
    }
   ],
   "source": [
    "subset_dataframe_by_year(\"C:\\\\Users\\\\vm-user\\\\Downloads\\\\All Datasets\\\\All Datasets\\\\aemo\\\\NSW_QLD_SA_TAS_VIC.csv\", 'SETTLEMENTDATE', 2020, 2025, \"C:\\\\Users\\\\vm-user\\\\Downloads\\\\dynamic\\\\NSW_QLD_SA_TAS_VIC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vm-user\\AppData\\Local\\Temp\\ipykernel_7916\\3140997336.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset[time_col] = subset[time_col].dt.strftime(\"%Y-%m-%d %H:%M\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset of data from 2020 to 2025 saved to C:\\Users\\vm-user\\Downloads\\dynamic\\nyiso_CAPITL_CENTRL_DUNWOD_GENESE_HUD VL_LONGIL_MHK VL_MILLWD_N.Y.C._NORTH_WEST.csv\n"
     ]
    }
   ],
   "source": [
    "subset_dataframe_by_year(\"C:\\\\Users\\\\vm-user\\\\Downloads\\\\All Datasets\\\\All Datasets\\\\nyiso\\\\nyiso_CAPITL_CENTRL_DUNWOD_GENESE_HUD VL_LONGIL_MHK VL_MILLWD_N.Y.C._NORTH_WEST.csv\", 'Time Stamp', 2020, 2025, \"C:\\\\Users\\\\vm-user\\\\Downloads\\\\dynamic\\\\nyiso_CAPITL_CENTRL_DUNWOD_GENESE_HUD VL_LONGIL_MHK VL_MILLWD_N.Y.C._NORTH_WEST.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python \"S:\\spatiotemporal-analysis\\spacetimeformer-main\\spacetimeformer\\train.py\" \"spacetimeformer\" \"aemo-dynamic\" --epochs \"100\" --context_points \"360\" --target_points \"48\" --run_name \"nsw_qld_dynamic\" --use_seasonal_decomp --l2_coeff \"0.0001\" --batch_size \"32\" --base_lr \"0.0001\" --learning_rate \"0.0001\" --d_model \"50\" --d_ff \"100\" --enc_layers \"1\" --dec_layers \"1\" --dropout_emb \".1\" --dropout_ff \".3\" --d_qk \"25\" --d_v \"25\" --n_heads \"2\" --patience \"5\" --data_path \"C:\\\\Users\\\\vm-user\\\\Downloads\\\\dynamic\\\\NSW_QLD_SA_TAS_VIC.csv\" --target_cols \"RRP_NSW\" --ignore_cols \"RRP_VIC-RRP_SA-RRP_TAS-TOTALDEMAND_NSW-TOTALDEMAND_QLD-TOTALDEMAND_SA-TOTALDEMAND_TAS-TOTALDEMAND_VIC\" --aemo_states \"NSW-QLD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
